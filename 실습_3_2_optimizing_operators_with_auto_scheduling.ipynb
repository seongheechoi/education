{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seongheechoi/education/blob/main/%EC%8B%A4%EC%8A%B5_3_2_optimizing_operators_with_auto_scheduling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TVM 실습자료 3.2: Optimizing Operators with Auto-scheduling**"
      ],
      "metadata": {
        "id": "8IWk0QXU9SQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4\n",
        "import numpy as np\n",
        "print(np.__version__)\n",
        "!pip list | grep numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU40sCXz9Rlc",
        "outputId": "9a02bcc3-0c60-4e7c-9170-58d80e0d952a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "1.26.4\n",
            "numpy                                 1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkIOT9rBz-dD",
        "outputId": "6aa1cdf1-4d54-4380-8005-df336c43974d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.1.1\n",
            "Collecting apache-tvm\n",
            "  Downloading apache_tvm-0.14.dev273-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (25.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (1.26.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (1.15.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (6.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (4.14.1)\n",
            "Downloading apache_tvm-0.14.dev273-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: apache-tvm\n",
            "Successfully installed apache-tvm-0.14.dev273\n"
          ]
        }
      ],
      "source": [
        "# Linux/MacOS CPU build only!\n",
        "# See tlcpack.ai for other pre-built binaries including CUDA\n",
        "!python -m pip install --upgrade pip\n",
        "!pip install apache-tvm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tvm\n",
        "from tvm import te, auto_scheduler"
      ],
      "metadata": {
        "id": "TvTKGUlV0Hwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Matrix Multiplication**"
      ],
      "metadata": {
        "id": "N00NtZC30LD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
        "def matmul_add(N, L, M, dtype):\n",
        "    A = te.placeholder((N, L), name=\"A\", dtype=dtype)\n",
        "    B = te.placeholder((L, M), name=\"B\", dtype=dtype)\n",
        "    C = te.placeholder((N, M), name=\"C\", dtype=dtype)\n",
        "\n",
        "    k = te.reduce_axis((0, L), name=\"k\")\n",
        "    matmul = te.compute(\n",
        "        (N, M),\n",
        "        lambda i, j: te.sum(A[i, k] * B[k, j], axis=k),\n",
        "        name=\"matmul\",\n",
        "        attrs={\"layout_free_placeholders\": [B]},  # enable automatic layout transform for tensor B\n",
        "    )\n",
        "    out = te.compute((N, M), lambda i, j: matmul[i, j] + C[i, j], name=\"out\")\n",
        "\n",
        "    return [A, B, C, out]"
      ],
      "metadata": {
        "id": "AsLyb2Gq0Mrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create the search task**"
      ],
      "metadata": {
        "id": "smRct2ZO0bpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = tvm.target.Target(\"llvm\")\n",
        "N = L = M = 1024\n",
        "task = tvm.auto_scheduler.SearchTask(func=matmul_add, args=(N, L, M, \"float32\"), target=target)\n",
        "\n",
        "# Inspect the computational graph\n",
        "print(\"Computational DAG:\")\n",
        "print(task.compute_dag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU1AMEHF0gx_",
        "outputId": "142beec8-9fea-414c-99d8-f6b9ea5ab33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computational DAG:\n",
            "A = PLACEHOLDER [1024, 1024]\n",
            "B = PLACEHOLDER [1024, 1024]\n",
            "matmul(i, j) += (A[i, k]*B[k, j])\n",
            "C = PLACEHOLDER [1024, 1024]\n",
            "out(i, j) = (matmul[i, j] + C[i, j])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Parameters for Auto-Scheduler**"
      ],
      "metadata": {
        "id": "Y27eepyJ0mQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_file = \"matmul.json\"\n",
        "tune_option = auto_scheduler.TuningOptions(\n",
        "    num_measure_trials=10,\n",
        "    measure_callbacks=[auto_scheduler.RecordToFile(log_file)],\n",
        "    verbose=2,\n",
        ")"
      ],
      "metadata": {
        "id": "7Y3OI8gX0nLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the search**"
      ],
      "metadata": {
        "id": "XqfhDN-J0pQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run auto-tuning (search)\n",
        "task.tune(tune_option)\n",
        "# Apply the best schedule\n",
        "sch, args = task.apply_best(log_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1qPOqe50qLQ",
        "outputId": "c2bac29b-1eda-4afe-e037-5a4d6c78a516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inspecting the Optimized Schedule**"
      ],
      "metadata": {
        "id": "7jQjJQaT0tZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lowered TIR:\")\n",
        "print(tvm.lower(sch, args, simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFJsaDU40u_z",
        "outputId": "8325ae14-050f-4c99-e88e-8152771f904d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowered TIR:\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\"), out: T.Buffer((1024, 1024), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        auto_scheduler_layout_transform = T.allocate([1048576], \"float32\", \"global\")\n",
            "        auto_scheduler_layout_transform_1 = T.Buffer((1048576,), data=auto_scheduler_layout_transform)\n",
            "        for ax0_ax1_fused_ax2_fused in T.parallel(8):\n",
            "            for ax4, ax5, ax6, ax7 in T.grid(32, 16, 32, 8):\n",
            "                B_1 = T.Buffer((1048576,), data=B.data)\n",
            "                auto_scheduler_layout_transform_1[ax0_ax1_fused_ax2_fused * 131072 + ax4 * 4096 + ax5 * 256 + ax6 * 8 + ax7] = B_1[ax4 * 32768 + ax6 * 1024 + ax0_ax1_fused_ax2_fused * 128 + ax5 * 8 + ax7]\n",
            "        for i_outer_outer_j_outer_outer_fused_i_outer_inner_fused in T.parallel(128):\n",
            "            matmul = T.allocate([4096], \"float32\", \"global\")\n",
            "            for j_outer_inner in range(2):\n",
            "                matmul_1 = T.Buffer((4096,), data=matmul)\n",
            "                for i_outer_inner_init, j_outer_inner_init in T.grid(4, 16):\n",
            "                    cse_var_1: T.int32 = i_outer_inner_init * 1024 + j_outer_inner_init * 8\n",
            "                    matmul_1[cse_var_1:cse_var_1 + 8] = T.Broadcast(T.float32(0), 8)\n",
            "                    matmul_1[cse_var_1 + 128:cse_var_1 + 128 + 8] = T.Broadcast(T.float32(0), 8)\n",
            "                    matmul_1[cse_var_1 + 256:cse_var_1 + 256 + 8] = T.Broadcast(T.float32(0), 8)\n",
            "                    matmul_1[cse_var_1 + 384:cse_var_1 + 384 + 8] = T.Broadcast(T.float32(0), 8)\n",
            "                    matmul_1[cse_var_1 + 512:cse_var_1 + 512 + 8] = T.Broadcast(T.float32(0), 8)\n",
            "                    matmul_1[cse_var_1 + 640:cse_var_1 + 640 + 8] = T.Broadcast(T.float32(0), 8)\n",
            "                    matmul_1[cse_var_1 + 768:cse_var_1 + 768 + 8] = T.Broadcast(T.float32(0), 8)\n",
            "                    matmul_1[cse_var_1 + 896:cse_var_1 + 896 + 8] = T.Broadcast(T.float32(0), 8)\n",
            "                for k_outer, i_outer_inner, j_outer_inner_1, k_inner in T.grid(32, 4, 16, 32):\n",
            "                    cse_var_11: T.int32 = i_outer_inner * 1024 + j_outer_inner_1 * 8\n",
            "                    cse_var_10: T.int32 = cse_var_11 + 896\n",
            "                    cse_var_9: T.int32 = cse_var_11 + 768\n",
            "                    cse_var_8: T.int32 = cse_var_11 + 640\n",
            "                    cse_var_7: T.int32 = cse_var_11 + 512\n",
            "                    cse_var_6: T.int32 = cse_var_11 + 384\n",
            "                    cse_var_5: T.int32 = cse_var_11 + 256\n",
            "                    cse_var_4: T.int32 = cse_var_11 + 128\n",
            "                    cse_var_3: T.int32 = i_outer_outer_j_outer_outer_fused_i_outer_inner_fused // 64 * 524288 + i_outer_outer_j_outer_outer_fused_i_outer_inner_fused % 16 * 32768 + i_outer_inner * 8192 + k_outer * 32 + k_inner\n",
            "                    cse_var_2: T.int32 = i_outer_outer_j_outer_outer_fused_i_outer_inner_fused % 64 // 16 * 262144 + j_outer_inner * 131072 + k_outer * 4096 + j_outer_inner_1 * 256 + k_inner * 8\n",
            "                    A_1 = T.Buffer((1048576,), data=A.data)\n",
            "                    matmul_1[cse_var_11:cse_var_11 + 8] = matmul_1[cse_var_11:cse_var_11 + 8] + T.Broadcast(A_1[cse_var_3], 8) * auto_scheduler_layout_transform_1[cse_var_2:cse_var_2 + 8]\n",
            "                    matmul_1[cse_var_4:cse_var_4 + 8] = matmul_1[cse_var_4:cse_var_4 + 8] + T.Broadcast(A_1[cse_var_3 + 1024], 8) * auto_scheduler_layout_transform_1[cse_var_2:cse_var_2 + 8]\n",
            "                    matmul_1[cse_var_5:cse_var_5 + 8] = matmul_1[cse_var_5:cse_var_5 + 8] + T.Broadcast(A_1[cse_var_3 + 2048], 8) * auto_scheduler_layout_transform_1[cse_var_2:cse_var_2 + 8]\n",
            "                    matmul_1[cse_var_6:cse_var_6 + 8] = matmul_1[cse_var_6:cse_var_6 + 8] + T.Broadcast(A_1[cse_var_3 + 3072], 8) * auto_scheduler_layout_transform_1[cse_var_2:cse_var_2 + 8]\n",
            "                    matmul_1[cse_var_7:cse_var_7 + 8] = matmul_1[cse_var_7:cse_var_7 + 8] + T.Broadcast(A_1[cse_var_3 + 4096], 8) * auto_scheduler_layout_transform_1[cse_var_2:cse_var_2 + 8]\n",
            "                    matmul_1[cse_var_8:cse_var_8 + 8] = matmul_1[cse_var_8:cse_var_8 + 8] + T.Broadcast(A_1[cse_var_3 + 5120], 8) * auto_scheduler_layout_transform_1[cse_var_2:cse_var_2 + 8]\n",
            "                    matmul_1[cse_var_9:cse_var_9 + 8] = matmul_1[cse_var_9:cse_var_9 + 8] + T.Broadcast(A_1[cse_var_3 + 6144], 8) * auto_scheduler_layout_transform_1[cse_var_2:cse_var_2 + 8]\n",
            "                    matmul_1[cse_var_10:cse_var_10 + 8] = matmul_1[cse_var_10:cse_var_10 + 8] + T.Broadcast(A_1[cse_var_3 + 7168], 8) * auto_scheduler_layout_transform_1[cse_var_2:cse_var_2 + 8]\n",
            "                for i_inner, j_inner in T.grid(32, 128):\n",
            "                    cse_var_12: T.int32 = i_outer_outer_j_outer_outer_fused_i_outer_inner_fused // 64 * 524288 + i_outer_outer_j_outer_outer_fused_i_outer_inner_fused % 16 * 32768 + i_inner * 1024 + i_outer_outer_j_outer_outer_fused_i_outer_inner_fused % 64 // 16 * 256 + j_outer_inner * 128 + j_inner\n",
            "                    out_1 = T.Buffer((1048576,), data=out.data)\n",
            "                    C_1 = T.Buffer((1048576,), data=C.data)\n",
            "                    out_1[cse_var_12] = matmul_1[i_inner * 128 + j_inner] + C_1[cse_var_12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check correctness and evaluate performance**"
      ],
      "metadata": {
        "id": "lNKpfK1F0y80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "func = tvm.build(sch, args, target)\n",
        "a_np = np.random.uniform(size=(N, L)).astype(np.float32)\n",
        "b_np = np.random.uniform(size=(L, M)).astype(np.float32)\n",
        "c_np = np.random.uniform(size=(N, M)).astype(np.float32)\n",
        "out_np = a_np.dot(b_np) + c_np\n",
        "\n",
        "dev = tvm.cpu()\n",
        "a_tvm = tvm.nd.array(a_np, device=dev)\n",
        "b_tvm = tvm.nd.array(b_np, device=dev)\n",
        "c_tvm = tvm.nd.array(c_np, device=dev)\n",
        "out_tvm = tvm.nd.empty(out_np.shape, device=dev)\n",
        "func(a_tvm, b_tvm, c_tvm, out_tvm)\n",
        "\n",
        "# Check results\n",
        "np.testing.assert_allclose(out_np, out_tvm.numpy(), rtol=1e-3)\n",
        "\n",
        "# Evaluate execution time.\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, min_repeat_ms=500)\n",
        "print(\n",
        "    \"Execution time of this operator: %.3f ms\"\n",
        "    % (np.median(evaluator(a_tvm, b_tvm, c_tvm, out_tvm).results) * 1000)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIXEpt2U0z1H",
        "outputId": "3622452b-d837-4c21-a21d-053bc62fa519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time of this operator: 215.292 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the record file**"
      ],
      "metadata": {
        "id": "HRJtDOvl06TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Equivalent python schedule:\")\n",
        "print(task.print_best(log_file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HQg5xlj07yj",
        "outputId": "40a375aa-9a6d-4927-cad9-80d80223a6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equivalent python schedule:\n",
            "matmul_i, matmul_j, matmul_k = tuple(matmul.op.axis) + tuple(matmul.op.reduce_axis)\n",
            "out_i, out_j = tuple(out.op.axis) + tuple(out.op.reduce_axis)\n",
            "matmul_i_o_i, matmul_i_i = s[matmul].split(matmul_i, factor=8)\n",
            "matmul_i_o_o_i, matmul_i_o_i = s[matmul].split(matmul_i_o_i, factor=4)\n",
            "matmul_i_o_o_o, matmul_i_o_o_i = s[matmul].split(matmul_i_o_o_i, factor=16)\n",
            "matmul_j_o_i, matmul_j_i = s[matmul].split(matmul_j, factor=8)\n",
            "matmul_j_o_o_i, matmul_j_o_i = s[matmul].split(matmul_j_o_i, factor=16)\n",
            "matmul_j_o_o_o, matmul_j_o_o_i = s[matmul].split(matmul_j_o_o_i, factor=2)\n",
            "matmul_k_o, matmul_k_i = s[matmul].split(matmul_k, factor=32)\n",
            "s[matmul].reorder(matmul_i_o_o_o, matmul_j_o_o_o, matmul_i_o_o_i, matmul_j_o_o_i, matmul_k_o, matmul_i_o_i, matmul_j_o_i, matmul_k_i, matmul_i_i, matmul_j_i)\n",
            "out_i_o_i, out_i_i = s[out].split(out_i, factor=32)\n",
            "out_i_o_o, out_i_o_i = s[out].split(out_i_o_i, factor=16)\n",
            "out_j_o_i, out_j_i = s[out].split(out_j, factor=128)\n",
            "out_j_o_o, out_j_o_i = s[out].split(out_j_o_i, factor=2)\n",
            "s[out].reorder(out_i_o_o, out_j_o_o, out_i_o_i, out_j_o_i, out_i_i, out_j_i)\n",
            "s[matmul].compute_at(s[out], out_j_o_i)\n",
            "out_i_o_o_j_o_o_fused_i_o_i_fused = s[out].fuse(out_i_o_o, out_j_o_o, out_i_o_i)\n",
            "s[out].parallel(out_i_o_o_j_o_o_fused_i_o_i_fused)\n",
            "s[matmul].pragma(matmul_i_o_o_o, \"auto_unroll_max_step\", 64)\n",
            "s[matmul].pragma(matmul_i_o_o_o, \"unroll_explicit\", True)\n",
            "s[matmul].vectorize(matmul_j_i)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}