{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seongheechoi/education/blob/main/%EC%8B%A4%EC%8A%B5_2_1_working_with_operators_using_tensor_expression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TVM 실습자료 2.1: Working with Operators Using Tensor Expression**"
      ],
      "metadata": {
        "id": "44zqc2HEOGwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4\n",
        "import numpy as np\n",
        "print(np.__version__)\n",
        "!pip list | grep numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "5jLW3mS1oYB7",
        "outputId": "87878ed3-e554-4ae0-d283-cb30712c4777"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m664.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "e46ed6fe18db4f9aba3ec9415fb34d26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n",
            "numpy                                 1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --upgrade pip\n",
        "!pip install apache-tvm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDA2fzfbzBbB",
        "outputId": "efbb8ab5-5bcc-426d-82a3-f5e02c31f46c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.1.1\n",
            "Collecting apache-tvm\n",
            "  Downloading apache_tvm-0.14.dev273-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (25.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (1.26.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (1.16.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (6.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (4.14.1)\n",
            "Downloading apache_tvm-0.14.dev273-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: apache-tvm\n",
            "Successfully installed apache-tvm-0.14.dev273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Example 1: Writing and Scheduling Vector Addition in TE for CPU**"
      ],
      "metadata": {
        "id": "pgYlvpnIOF8h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SDOeCmZUyoSK"
      },
      "outputs": [],
      "source": [
        "import tvm\n",
        "import tvm.testing\n",
        "from tvm import te\n",
        "import numpy as np\n",
        "\n",
        "tgt = tvm.target.Target(target=\"llvm\", host=\"llvm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = te.var(\"n\")\n",
        "A = te.placeholder((n,), name=\"A\")\n",
        "B = te.placeholder((n,), name=\"B\")\n",
        "C = te.compute(A.shape, lambda i: A[i] + B[i], name=\"C\")"
      ],
      "metadata": {
        "id": "93nB60K2zexz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = te.create_schedule(C.op)"
      ],
      "metadata": {
        "id": "lruFEY_tzqdP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fadd = tvm.build(s, [A, B, C], tgt, name=\"myadd\")"
      ],
      "metadata": {
        "id": "Rg__70W0ztXm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev = tvm.device(tgt.kind.name, 0)\n",
        "\n",
        "n = 1024\n",
        "a = tvm.nd.array(np.random.uniform(size=n).astype(A.dtype), dev)\n",
        "b = tvm.nd.array(np.random.uniform(size=n).astype(B.dtype), dev)\n",
        "c = tvm.nd.array(np.zeros(n, dtype=C.dtype), dev)\n",
        "fadd(a, b, c)\n",
        "tvm.testing.assert_allclose(c.numpy(), a.numpy() + b.numpy())"
      ],
      "metadata": {
        "id": "mIl6w23Wzy3y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "np_repeat = 100\n",
        "np_running_time = timeit.timeit(\n",
        "    setup=\"import numpy\\n\"\n",
        "    \"n = 32768\\n\"\n",
        "    'dtype = \"float32\"\\n'\n",
        "    \"a = numpy.random.rand(n, 1).astype(dtype)\\n\"\n",
        "    \"b = numpy.random.rand(n, 1).astype(dtype)\\n\",\n",
        "    stmt=\"answer = a + b\",\n",
        "    number=np_repeat,\n",
        ")\n",
        "print(\"Numpy running time: %f\" % (np_running_time / np_repeat))\n",
        "\n",
        "\n",
        "def evaluate_addition(func, target, optimization, log):\n",
        "    dev = tvm.device(target.kind.name, 0)\n",
        "    n = 32768\n",
        "    a = tvm.nd.array(np.random.uniform(size=n).astype(A.dtype), dev)\n",
        "    b = tvm.nd.array(np.random.uniform(size=n).astype(B.dtype), dev)\n",
        "    c = tvm.nd.array(np.zeros(n, dtype=C.dtype), dev)\n",
        "\n",
        "    evaluator = func.time_evaluator(func.entry_name, dev, number=10)\n",
        "    mean_time = evaluator(a, b, c).mean\n",
        "    print(\"%s: %f\" % (optimization, mean_time))\n",
        "\n",
        "    log.append((optimization, mean_time))\n",
        "\n",
        "\n",
        "log = [(\"numpy\", np_running_time / np_repeat)]\n",
        "evaluate_addition(fadd, tgt, \"naive\", log=log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syuClFnbz9-X",
        "outputId": "80d259de-f277-40ef-80a4-bb9056681ea3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy running time: 0.000008\n",
            "naive: 0.000006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svDGdjix0kAt",
        "outputId": "827edda2-9b3f-42c2-f378-43a09b158435"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        n = T.int32()\n",
            "        A_1 = T.match_buffer(A, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        C_1 = T.match_buffer(C, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        for i in range(n):\n",
            "            C_2 = T.Buffer((C_1.strides[0] * n,), data=C_1.data, buffer_type=\"auto\")\n",
            "            A_2 = T.Buffer((A_1.strides[0] * n,), data=A_1.data, buffer_type=\"auto\")\n",
            "            B_2 = T.Buffer((B_1.strides[0] * n,), data=B_1.data, buffer_type=\"auto\")\n",
            "            C_2[i * C_1.strides[0]] = A_2[i * A_1.strides[0]] + B_2[i * B_1.strides[0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s[C].parallel(C.op.axis[0])"
      ],
      "metadata": {
        "id": "-n8GvALN0lDJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP68hF5K0nTs",
        "outputId": "8aeff838-0007-429b-8240-0df4fbd62580"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        n = T.int32()\n",
            "        A_1 = T.match_buffer(A, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        C_1 = T.match_buffer(C, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        for i in T.parallel(n):\n",
            "            C_2 = T.Buffer((C_1.strides[0] * n,), data=C_1.data, buffer_type=\"auto\")\n",
            "            A_2 = T.Buffer((A_1.strides[0] * n,), data=A_1.data, buffer_type=\"auto\")\n",
            "            B_2 = T.Buffer((B_1.strides[0] * n,), data=B_1.data, buffer_type=\"auto\")\n",
            "            C_2[i * C_1.strides[0]] = A_2[i * A_1.strides[0]] + B_2[i * B_1.strides[0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fadd_parallel = tvm.build(s, [A, B, C], tgt, name=\"myadd_parallel\")\n",
        "fadd_parallel(a, b, c)\n",
        "\n",
        "tvm.testing.assert_allclose(c.numpy(), a.numpy() + b.numpy())\n",
        "\n",
        "evaluate_addition(fadd_parallel, tgt, \"parallel\", log=log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve4ghSxE1yCT",
        "outputId": "558a98d3-1ff3-439d-f9fb-1bf28450073d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parallel: 0.000014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the schedule, since we modified it with the parallel operation in\n",
        "# the previous example\n",
        "n = te.var(\"n\")\n",
        "A = te.placeholder((n,), name=\"A\")\n",
        "B = te.placeholder((n,), name=\"B\")\n",
        "C = te.compute(A.shape, lambda i: A[i] + B[i], name=\"C\")\n",
        "\n",
        "s = te.create_schedule(C.op)\n",
        "\n",
        "# This factor should be chosen to match the number of threads appropriate for\n",
        "# your CPU. This will vary depending on architecture, but a good rule is\n",
        "# setting this factor to equal the number of available CPU cores.\n",
        "factor = 2\n",
        "\n",
        "outer, inner = s[C].split(C.op.axis[0], factor=factor)\n",
        "s[C].parallel(outer)\n",
        "s[C].vectorize(inner)\n",
        "\n",
        "fadd_vector = tvm.build(s, [A, B, C], tgt, name=\"myadd_parallel\")\n",
        "\n",
        "evaluate_addition(fadd_vector, tgt, \"vector\", log=log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7fTlCFk2I_G",
        "outputId": "9e40ef7f-de95-475a-83c2-b54bc19fa50d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector: 0.000031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NXlXTRg2URh",
        "outputId": "75365ad1-8d78-45a2-8580-e4060804c2e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        n = T.int32()\n",
            "        A_1 = T.match_buffer(A, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        C_1 = T.match_buffer(C, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        for i_outer in T.parallel((n + 1) // 2):\n",
            "            for i_inner_s in range(2):\n",
            "                if T.likely(i_outer * 2 + i_inner_s < n):\n",
            "                    C_2 = T.Buffer((C_1.strides[0] * n,), data=C_1.data, buffer_type=\"auto\")\n",
            "                    A_2 = T.Buffer((A_1.strides[0] * n,), data=A_1.data, buffer_type=\"auto\")\n",
            "                    B_2 = T.Buffer((B_1.strides[0] * n,), data=B_1.data, buffer_type=\"auto\")\n",
            "                    cse_var_1: T.int32 = i_outer * 2 + i_inner_s\n",
            "                    C_2[cse_var_1 * C_1.strides[0]] = A_2[cse_var_1 * A_1.strides[0]] + B_2[cse_var_1 * B_1.strides[0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = log[0][1]\n",
        "print(\"%s\\t%s\\t%s\" % (\"Operator\".rjust(20), \"Timing\".rjust(20), \"Performance\".rjust(20)))\n",
        "for result in log:\n",
        "    print(\n",
        "        \"%s\\t%s\\t%s\"\n",
        "        % (result[0].rjust(20), str(result[1]).rjust(20), str(result[1] / baseline).rjust(20))\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WdMqAFa3SG9",
        "outputId": "2b1fb031-f15a-477e-b41d-b21e2f7cb3d2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Operator\t              Timing\t         Performance\n",
            "               numpy\t7.870489999959318e-06\t                 1.0\n",
            "               naive\t           5.767e-06\t  0.7327370976940202\n",
            "            parallel\t          1.3977e-05\t  1.7758741831921832\n",
            "              vector\t         3.08981e-05\t   3.925816562902654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving and Loading Compiled Modules**"
      ],
      "metadata": {
        "id": "1X-dPmieOhOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tvm.contrib import cc\n",
        "from tvm.contrib import utils\n",
        "\n",
        "temp = utils.tempdir()\n",
        "fadd.save(temp.relpath(\"myadd.o\"))\n",
        "if tgt.kind.name == \"cuda\":\n",
        "    fadd.imported_modules[0].save(temp.relpath(\"myadd.ptx\"))\n",
        "if tgt.kind.name == \"rocm\":\n",
        "    fadd.imported_modules[0].save(temp.relpath(\"myadd.hsaco\"))\n",
        "if tgt.kind.name.startswith(\"opencl\"):\n",
        "    fadd.imported_modules[0].save(temp.relpath(\"myadd.cl\"))\n",
        "cc.create_shared(temp.relpath(\"myadd.so\"), [temp.relpath(\"myadd.o\")])\n",
        "print(temp.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUsuR7OA4W3A",
        "outputId": "dfc62780-e78f-4f29-aabe-d87b5c7f991f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['myadd.o', 'myadd.so']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fadd1 = tvm.runtime.load_module(temp.relpath(\"myadd.so\"))\n",
        "if tgt.kind.name == \"cuda\":\n",
        "    fadd1_dev = tvm.runtime.load_module(temp.relpath(\"myadd.ptx\"))\n",
        "    fadd1.import_module(fadd1_dev)\n",
        "\n",
        "if tgt.kind.name == \"rocm\":\n",
        "    fadd1_dev = tvm.runtime.load_module(temp.relpath(\"myadd.hsaco\"))\n",
        "    fadd1.import_module(fadd1_dev)\n",
        "\n",
        "if tgt.kind.name.startswith(\"opencl\"):\n",
        "    fadd1_dev = tvm.runtime.load_module(temp.relpath(\"myadd.cl\"))\n",
        "    fadd1.import_module(fadd1_dev)\n",
        "\n",
        "fadd1(a, b, c)\n",
        "tvm.testing.assert_allclose(c.numpy(), a.numpy() + b.numpy())"
      ],
      "metadata": {
        "id": "bZ1gPkZx40PZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fadd.export_library(temp.relpath(\"myadd_pack.so\"))\n",
        "fadd2 = tvm.runtime.load_module(temp.relpath(\"myadd_pack.so\"))\n",
        "fadd2(a, b, c)\n",
        "tvm.testing.assert_allclose(c.numpy(), a.numpy() + b.numpy())"
      ],
      "metadata": {
        "id": "X925se4g41MA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if tgt.kind.name.startswith(\"opencl\"):\n",
        "    fadd_cl = tvm.build(s, [A, B, C], tgt, name=\"myadd\")\n",
        "    print(\"------opencl code------\")\n",
        "    print(fadd_cl.imported_modules[0].get_source())\n",
        "    dev = tvm.cl(0)\n",
        "    n = 1024\n",
        "    a = tvm.nd.array(np.random.uniform(size=n).astype(A.dtype), dev)\n",
        "    b = tvm.nd.array(np.random.uniform(size=n).astype(B.dtype), dev)\n",
        "    c = tvm.nd.array(np.zeros(n, dtype=C.dtype), dev)\n",
        "    fadd_cl(a, b, c)\n",
        "    tvm.testing.assert_allclose(c.numpy(), a.numpy() + b.numpy())"
      ],
      "metadata": {
        "id": "ED9VmwIT5CmZ",
        "collapsed": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Example 2: Manually Optimizing Matrix Multiplication with TE**"
      ],
      "metadata": {
        "id": "7PJLfzZtOtoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm\n",
        "import tvm.testing\n",
        "from tvm import te\n",
        "import numpy\n",
        "\n",
        "# The size of the matrix\n",
        "# (M, K) x (K, N)\n",
        "# You are free to try out different shapes, sometimes TVM optimization outperforms numpy with MKL.\n",
        "M = 1024\n",
        "K = 1024\n",
        "N = 1024\n",
        "\n",
        "# The default tensor data type in tvm\n",
        "dtype = \"float32\"\n",
        "\n",
        "# You will want to adjust the target to match any CPU vector extensions you\n",
        "# might have. For example, if you're using using Intel AVX2 (Advanced Vector\n",
        "# Extensions) ISA for SIMD, you can get the best performance by changing the\n",
        "# following line to ``llvm -mcpu=core-avx2``, or specific type of CPU you use.\n",
        "# Recall that you're using llvm, you can get this information from the command\n",
        "# ``llc --version`` to get the CPU type, and you can check ``/proc/cpuinfo``\n",
        "# for additional extensions that your processor might support.\n",
        "\n",
        "target = tvm.target.Target(target=\"llvm\", host=\"llvm\")\n",
        "dev = tvm.device(target.kind.name, 0)\n",
        "\n",
        "# Random generated tensor for testing\n",
        "a = tvm.nd.array(numpy.random.rand(M, K).astype(dtype), dev)\n",
        "b = tvm.nd.array(numpy.random.rand(K, N).astype(dtype), dev)\n",
        "\n",
        "# Repeatedly perform a matrix multiplication to get a performance baseline\n",
        "# for the default numpy implementation\n",
        "np_repeat = 100\n",
        "np_running_time = timeit.timeit(\n",
        "    setup=\"import numpy\\n\"\n",
        "    \"M = \" + str(M) + \"\\n\"\n",
        "    \"K = \" + str(K) + \"\\n\"\n",
        "    \"N = \" + str(N) + \"\\n\"\n",
        "    'dtype = \"float32\"\\n'\n",
        "    \"a = numpy.random.rand(M, K).astype(dtype)\\n\"\n",
        "    \"b = numpy.random.rand(K, N).astype(dtype)\\n\",\n",
        "    stmt=\"answer = numpy.dot(a, b)\",\n",
        "    number=np_repeat,\n",
        ")\n",
        "print(\"Numpy running time: %f\" % (np_running_time / np_repeat))\n",
        "\n",
        "answer = numpy.dot(a.numpy(), b.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXEUkiXK5c3U",
        "outputId": "0682d6b3-8e6a-4450-fc73-1db997e2e73a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy running time: 0.024897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TVM Matrix Multiplication using TE\n",
        "k = te.reduce_axis((0, K), \"k\")\n",
        "A = te.placeholder((M, K), name=\"A\")\n",
        "B = te.placeholder((K, N), name=\"B\")\n",
        "C = te.compute((M, N), lambda x, y: te.sum(A[x, k] * B[k, y], axis=k), name=\"C\")\n",
        "\n",
        "# Default schedule\n",
        "s = te.create_schedule(C.op)\n",
        "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
        "\n",
        "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), dev)\n",
        "func(a, b, c)\n",
        "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)\n",
        "\n",
        "\n",
        "def evaluate_operation(s, vars, target, name, optimization, log):\n",
        "    func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
        "    assert func\n",
        "\n",
        "    c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), dev)\n",
        "    func(a, b, c)\n",
        "    tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)\n",
        "\n",
        "    evaluator = func.time_evaluator(func.entry_name, dev, number=10)\n",
        "    mean_time = evaluator(a, b, c).mean\n",
        "    print(\"%s: %f\" % (optimization, mean_time))\n",
        "    log.append((optimization, mean_time))\n",
        "\n",
        "\n",
        "log = []\n",
        "\n",
        "evaluate_operation(s, [A, B, C], target=target, name=\"mmult\", optimization=\"none\", log=log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PmbpjWQ5vn8",
        "outputId": "c274b0d9-8a6d-4163-b073-60221e2d7f79"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "none: 6.767832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZVxraVV5w8Y",
        "outputId": "36822ff0-9fb2-495a-c184-e3e963a37684"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for x, y in T.grid(1024, 1024):\n",
            "            C_1 = T.Buffer((1048576,), data=C.data)\n",
            "            C_1[x * 1024 + y] = T.float32(0)\n",
            "            for k in range(1024):\n",
            "                cse_var_2: T.int32 = x * 1024\n",
            "                cse_var_1: T.int32 = cse_var_2 + y\n",
            "                A_1 = T.Buffer((1048576,), data=A.data)\n",
            "                B_1 = T.Buffer((1048576,), data=B.data)\n",
            "                C_1[cse_var_1] = C_1[cse_var_1] + A_1[cse_var_2 + k] * B_1[k * 1024 + y]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = te.create_schedule(C.op)\n",
        "bn = 32\n",
        "\n",
        "# Blocking by loop tiling\n",
        "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
        "(k,) = s[C].op.reduce_axis\n",
        "ko, ki = s[C].split(k, factor=4)\n",
        "\n",
        "# Hoist reduction domain outside the blocking loop\n",
        "s[C].reorder(xo, yo, ko, ki, xi, yi)\n",
        "\n",
        "evaluate_operation(s, [A, B, C], target=target, name=\"mmult\", optimization=\"blocking\", log=log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6vL9mvTGQqO",
        "outputId": "ec490657-87a6-4387-9fe3-241d305fc826"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blocking: 0.347370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bn 32   blocking: 0.302861"
      ],
      "metadata": {
        "id": "zBQIk-KGRObA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = te.create_schedule(C.op)\n",
        "bn = 16\n",
        "\n",
        "# Blocking by loop tiling\n",
        "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
        "(k,) = s[C].op.reduce_axis\n",
        "ko, ki = s[C].split(k, factor=4)\n",
        "\n",
        "# Hoist reduction domain outside the blocking loop\n",
        "s[C].reorder(xo, yo, ko, ki, xi, yi)\n",
        "\n",
        "evaluate_operation(s, [A, B, C], target=target, name=\"mmult\", optimization=\"blocking\", log=log)"
      ],
      "metadata": {
        "id": "kLo1guV4RcSu",
        "outputId": "9164a6c5-0da3-4c3b-b08e-d42985885554",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blocking: 0.586391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LN3owVqhS201"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = te.create_schedule(C.op)\n",
        "bn = 64\n",
        "\n",
        "# Blocking by loop tiling\n",
        "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
        "(k,) = s[C].op.reduce_axis\n",
        "ko, ki = s[C].split(k, factor=4)\n",
        "\n",
        "# Hoist reduction domain outside the blocking loop\n",
        "s[C].reorder(xo, yo, ko, ki, xi, yi)\n",
        "\n",
        "evaluate_operation(s, [A, B, C], target=target, name=\"mmult\", optimization=\"blocking\", log=log)"
      ],
      "metadata": {
        "id": "Qgc4yqaER2RD",
        "outputId": "8d68b123-2baa-410d-c8c0-26a1df67d0e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blocking: 0.157779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = te.create_schedule(C.op)\n",
        "bn = 128\n",
        "\n",
        "# Blocking by loop tiling\n",
        "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
        "(k,) = s[C].op.reduce_axis\n",
        "ko, ki = s[C].split(k, factor=4)\n",
        "\n",
        "# Hoist reduction domain outside the blocking loop\n",
        "s[C].reorder(xo, yo, ko, ki, xi, yi)\n",
        "\n",
        "evaluate_operation(s, [A, B, C], target=target, name=\"mmult\", optimization=\"blocking\", log=log)"
      ],
      "metadata": {
        "id": "o4yOWiHIR5lw",
        "outputId": "2ad91530-3ee5-44b2-d085-91fe2743c6a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blocking: 0.144834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = te.create_schedule(C.op)\n",
        "bn = 256\n",
        "\n",
        "# Blocking by loop tiling\n",
        "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
        "(k,) = s[C].op.reduce_axis\n",
        "ko, ki = s[C].split(k, factor=4)\n",
        "\n",
        "# Hoist reduction domain outside the blocking loop\n",
        "s[C].reorder(xo, yo, ko, ki, xi, yi)\n",
        "\n",
        "evaluate_operation(s, [A, B, C], target=target, name=\"mmult\", optimization=\"blocking\", log=log)"
      ],
      "metadata": {
        "id": "N7Bh1oSmR8LD",
        "outputId": "4734f33b-2556-4129-f2ed-376a3d3dcc5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blocking: 0.185125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTw1DmZPGZ5k",
        "outputId": "3217bf9a-7d87-4e32-c64b-709f3952dc48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for x_outer, y_outer in T.grid(32, 32):\n",
            "            C_1 = T.Buffer((1048576,), data=C.data)\n",
            "            for x_inner_init, y_inner_init in T.grid(32, 32):\n",
            "                C_1[x_outer * 32768 + x_inner_init * 1024 + y_outer * 32 + y_inner_init] = T.float32(0)\n",
            "            for k_outer, k_inner, x_inner, y_inner in T.grid(256, 4, 32, 32):\n",
            "                cse_var_3: T.int32 = y_outer * 32\n",
            "                cse_var_2: T.int32 = x_outer * 32768 + x_inner * 1024\n",
            "                cse_var_1: T.int32 = cse_var_2 + cse_var_3 + y_inner\n",
            "                A_1 = T.Buffer((1048576,), data=A.data)\n",
            "                B_1 = T.Buffer((1048576,), data=B.data)\n",
            "                C_1[cse_var_1] = C_1[cse_var_1] + A_1[cse_var_2 + k_outer * 4 + k_inner] * B_1[k_outer * 4096 + k_inner * 1024 + cse_var_3 + y_inner]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the vectorization optimization\n",
        "s[C].vectorize(yi)\n",
        "\n",
        "evaluate_operation(s, [A, B, C], target=target, name=\"mmult\", optimization=\"vectorization\", log=log)\n",
        "\n",
        "# The generalized IR after vectorization\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWeQWTDNH0-r",
        "outputId": "83a8ab6e-e42d-40d1-b364-65e6596365bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vectorization: 0.429523\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for x_outer, y_outer in T.grid(32, 32):\n",
            "            C_1 = T.Buffer((1048576,), data=C.data)\n",
            "            for x_inner_init in range(32):\n",
            "                C_1[x_outer * 32768 + x_inner_init * 1024 + y_outer * 32:x_outer * 32768 + x_inner_init * 1024 + y_outer * 32 + 32] = T.Broadcast(T.float32(0), 32)\n",
            "            for k_outer, k_inner, x_inner in T.grid(256, 4, 32):\n",
            "                cse_var_3: T.int32 = y_outer * 32\n",
            "                cse_var_2: T.int32 = x_outer * 32768 + x_inner * 1024\n",
            "                cse_var_1: T.int32 = cse_var_2 + cse_var_3\n",
            "                A_1 = T.Buffer((1048576,), data=A.data)\n",
            "                B_1 = T.Buffer((1048576,), data=B.data)\n",
            "                C_1[cse_var_1:cse_var_1 + 32] = C_1[cse_var_1:cse_var_1 + 32] + T.Broadcast(A_1[cse_var_2 + k_outer * 4 + k_inner], 32) * B_1[k_outer * 4096 + k_inner * 1024 + cse_var_3:k_outer * 4096 + k_inner * 1024 + cse_var_3 + 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = te.create_schedule(C.op)\n",
        "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
        "(k,) = s[C].op.reduce_axis\n",
        "ko, ki = s[C].split(k, factor=4)\n",
        "\n",
        "# re-ordering\n",
        "s[C].reorder(xo, yo, ko, xi, ki, yi)\n",
        "s[C].vectorize(yi)\n",
        "\n",
        "evaluate_operation(\n",
        "    s, [A, B, C], target=target, name=\"mmult\", optimization=\"loop permutation\", log=log\n",
        ")\n",
        "\n",
        "# Again, print the new generalized IR\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOLDfKEMInTl",
        "outputId": "f03b5326-d6c9-49f8-a7db-05a1d87dd272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loop permutation: 0.192014\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for x_outer, y_outer in T.grid(32, 32):\n",
            "            C_1 = T.Buffer((1048576,), data=C.data)\n",
            "            for x_inner_init in range(32):\n",
            "                C_1[x_outer * 32768 + x_inner_init * 1024 + y_outer * 32:x_outer * 32768 + x_inner_init * 1024 + y_outer * 32 + 32] = T.Broadcast(T.float32(0), 32)\n",
            "            for k_outer, x_inner, k_inner in T.grid(256, 32, 4):\n",
            "                cse_var_3: T.int32 = y_outer * 32\n",
            "                cse_var_2: T.int32 = x_outer * 32768 + x_inner * 1024\n",
            "                cse_var_1: T.int32 = cse_var_2 + cse_var_3\n",
            "                A_1 = T.Buffer((1048576,), data=A.data)\n",
            "                B_1 = T.Buffer((1048576,), data=B.data)\n",
            "                C_1[cse_var_1:cse_var_1 + 32] = C_1[cse_var_1:cse_var_1 + 32] + T.Broadcast(A_1[cse_var_2 + k_outer * 4 + k_inner], 32) * B_1[k_outer * 4096 + k_inner * 1024 + cse_var_3:k_outer * 4096 + k_inner * 1024 + cse_var_3 + 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We have to re-write the algorithm slightly.\n",
        "packedB = te.compute((N / bn, K, bn), lambda x, y, z: B[y, x * bn + z], name=\"packedB\")\n",
        "C = te.compute(\n",
        "    (M, N),\n",
        "    lambda x, y: te.sum(A[x, k] * packedB[y // bn, k, tvm.tir.indexmod(y, bn)], axis=k),\n",
        "    name=\"C\",\n",
        ")\n",
        "\n",
        "s = te.create_schedule(C.op)"
      ],
      "metadata": {
        "id": "1OIObT77IpRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
        "(k,) = s[C].op.reduce_axis\n",
        "ko, ki = s[C].split(k, factor=4)\n",
        "\n",
        "s[C].reorder(xo, yo, ko, xi, ki, yi)\n",
        "s[C].vectorize(yi)\n",
        "\n",
        "x, y, z = s[packedB].op.axis\n",
        "s[packedB].vectorize(z)\n",
        "s[packedB].parallel(x)\n",
        "\n",
        "evaluate_operation(s, [A, B, C], target=target, name=\"mmult\", optimization=\"array packing\", log=log)\n",
        "\n",
        "# Here is the generated IR after array packing.\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW9UR5wMI6hI",
        "outputId": "f7ff8f28-58ca-4175-b83e-9a09d7ba57a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array packing: 0.148654\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        packedB = T.allocate([32768], \"float32x32\", \"global\")\n",
            "        packedB_1 = T.Buffer((32768,), \"float32x32\", data=packedB)\n",
            "        for x in T.parallel(32):\n",
            "            for y in range(1024):\n",
            "                B_1 = T.Buffer((1048576,), data=B.data)\n",
            "                packedB_1[x * 1024 + y] = B_1[y * 1024 + x * 32:y * 1024 + x * 32 + 32]\n",
            "        for x_outer, y_outer in T.grid(32, 32):\n",
            "            C_1 = T.Buffer((1048576,), data=C.data)\n",
            "            for x_inner_init in range(32):\n",
            "                C_1[x_outer * 32768 + x_inner_init * 1024 + y_outer * 32:x_outer * 32768 + x_inner_init * 1024 + y_outer * 32 + 32] = T.Broadcast(T.float32(0), 32)\n",
            "            for k_outer, x_inner, k_inner in T.grid(256, 32, 4):\n",
            "                cse_var_3: T.int32 = x_outer * 32768 + x_inner * 1024\n",
            "                cse_var_2: T.int32 = k_outer * 4\n",
            "                cse_var_1: T.int32 = cse_var_3 + y_outer * 32\n",
            "                A_1 = T.Buffer((1048576,), data=A.data)\n",
            "                C_1[cse_var_1:cse_var_1 + 32] = C_1[cse_var_1:cse_var_1 + 32] + T.Broadcast(A_1[cse_var_3 + cse_var_2 + k_inner], 32) * packedB_1[y_outer * 1024 + cse_var_2 + k_inner]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = te.create_schedule(C.op)\n",
        "\n",
        "# Allocate write cache\n",
        "CC = s.cache_write(C, \"global\")\n",
        "\n",
        "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
        "\n",
        "# Write cache is computed at yo\n",
        "s[CC].compute_at(s[C], yo)\n",
        "\n",
        "# New inner axes\n",
        "xc, yc = s[CC].op.axis\n",
        "\n",
        "(k,) = s[CC].op.reduce_axis\n",
        "ko, ki = s[CC].split(k, factor=4)\n",
        "s[CC].reorder(ko, xc, ki, yc)\n",
        "s[CC].unroll(ki)\n",
        "s[CC].vectorize(yc)\n",
        "\n",
        "x, y, z = s[packedB].op.axis\n",
        "s[packedB].vectorize(z)\n",
        "s[packedB].parallel(x)"
      ],
      "metadata": {
        "id": "88lOvenTI7jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_operation(s, [A, B, C], target=target, name=\"mmult\", optimization=\"block caching\", log=log)\n",
        "\n",
        "# Here is the generated IR after write cache blocking.\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjGQr36RJy48",
        "outputId": "476e6b7a-2e2e-4253-9324-368632554148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "block caching: 0.129115\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        packedB = T.allocate([32768], \"float32x32\", \"global\")\n",
            "        C_global = T.allocate([1024], \"float32\", \"global\")\n",
            "        packedB_1 = T.Buffer((32768,), \"float32x32\", data=packedB)\n",
            "        for x in T.parallel(32):\n",
            "            for y in range(1024):\n",
            "                B_1 = T.Buffer((1048576,), data=B.data)\n",
            "                packedB_1[x * 1024 + y] = B_1[y * 1024 + x * 32:y * 1024 + x * 32 + 32]\n",
            "        for x_outer, y_outer in T.grid(32, 32):\n",
            "            C_global_1 = T.Buffer((1024,), data=C_global)\n",
            "            for x_c_init in range(32):\n",
            "                C_global_1[x_c_init * 32:x_c_init * 32 + 32] = T.Broadcast(T.float32(0), 32)\n",
            "            for k_outer, x_c in T.grid(256, 32):\n",
            "                cse_var_4: T.int32 = k_outer * 4\n",
            "                cse_var_3: T.int32 = x_c * 32\n",
            "                cse_var_2: T.int32 = y_outer * 1024 + cse_var_4\n",
            "                cse_var_1: T.int32 = x_outer * 32768 + x_c * 1024 + cse_var_4\n",
            "                A_1 = T.Buffer((1048576,), data=A.data)\n",
            "                C_global_1[cse_var_3:cse_var_3 + 32] = C_global_1[cse_var_3:cse_var_3 + 32] + T.Broadcast(A_1[cse_var_1], 32) * packedB_1[cse_var_2]\n",
            "                C_global_1[cse_var_3:cse_var_3 + 32] = C_global_1[cse_var_3:cse_var_3 + 32] + T.Broadcast(A_1[cse_var_1 + 1], 32) * packedB_1[cse_var_2 + 1]\n",
            "                C_global_1[cse_var_3:cse_var_3 + 32] = C_global_1[cse_var_3:cse_var_3 + 32] + T.Broadcast(A_1[cse_var_1 + 2], 32) * packedB_1[cse_var_2 + 2]\n",
            "                C_global_1[cse_var_3:cse_var_3 + 32] = C_global_1[cse_var_3:cse_var_3 + 32] + T.Broadcast(A_1[cse_var_1 + 3], 32) * packedB_1[cse_var_2 + 3]\n",
            "            for x_inner, y_inner in T.grid(32, 32):\n",
            "                C_1 = T.Buffer((1048576,), data=C.data)\n",
            "                C_1[x_outer * 32768 + x_inner * 1024 + y_outer * 32 + y_inner] = C_global_1[x_inner * 32 + y_inner]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parallel\n",
        "s[C].parallel(xo)\n",
        "\n",
        "x, y, z = s[packedB].op.axis\n",
        "s[packedB].vectorize(z)\n",
        "s[packedB].parallel(x)\n",
        "\n",
        "evaluate_operation(\n",
        "    s, [A, B, C], target=target, name=\"mmult\", optimization=\"parallelization\", log=log\n",
        ")\n",
        "\n",
        "# Here is the generated IR after parallelization.\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "873oZ-ILLpTo",
        "outputId": "a133b09f-eb1f-4675-e9d7-0d9afe0e0bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parallelization: 0.207919\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        packedB = T.allocate([32768], \"float32x32\", \"global\")\n",
            "        packedB_1 = T.Buffer((32768,), \"float32x32\", data=packedB)\n",
            "        for x in T.parallel(32):\n",
            "            for y in range(1024):\n",
            "                B_1 = T.Buffer((1048576,), data=B.data)\n",
            "                packedB_1[x * 1024 + y] = B_1[y * 1024 + x * 32:y * 1024 + x * 32 + 32]\n",
            "        for x_outer in T.parallel(32):\n",
            "            C_global = T.allocate([1024], \"float32\", \"global\")\n",
            "            for y_outer in range(32):\n",
            "                C_global_1 = T.Buffer((1024,), data=C_global)\n",
            "                for x_c_init in range(32):\n",
            "                    C_global_1[x_c_init * 32:x_c_init * 32 + 32] = T.Broadcast(T.float32(0), 32)\n",
            "                for k_outer, x_c in T.grid(256, 32):\n",
            "                    cse_var_4: T.int32 = k_outer * 4\n",
            "                    cse_var_3: T.int32 = x_c * 32\n",
            "                    cse_var_2: T.int32 = y_outer * 1024 + cse_var_4\n",
            "                    cse_var_1: T.int32 = x_outer * 32768 + x_c * 1024 + cse_var_4\n",
            "                    A_1 = T.Buffer((1048576,), data=A.data)\n",
            "                    C_global_1[cse_var_3:cse_var_3 + 32] = C_global_1[cse_var_3:cse_var_3 + 32] + T.Broadcast(A_1[cse_var_1], 32) * packedB_1[cse_var_2]\n",
            "                    C_global_1[cse_var_3:cse_var_3 + 32] = C_global_1[cse_var_3:cse_var_3 + 32] + T.Broadcast(A_1[cse_var_1 + 1], 32) * packedB_1[cse_var_2 + 1]\n",
            "                    C_global_1[cse_var_3:cse_var_3 + 32] = C_global_1[cse_var_3:cse_var_3 + 32] + T.Broadcast(A_1[cse_var_1 + 2], 32) * packedB_1[cse_var_2 + 2]\n",
            "                    C_global_1[cse_var_3:cse_var_3 + 32] = C_global_1[cse_var_3:cse_var_3 + 32] + T.Broadcast(A_1[cse_var_1 + 3], 32) * packedB_1[cse_var_2 + 3]\n",
            "                for x_inner, y_inner in T.grid(32, 32):\n",
            "                    C_1 = T.Buffer((1048576,), data=C.data)\n",
            "                    C_1[x_outer * 32768 + x_inner * 1024 + y_outer * 32 + y_inner] = C_global_1[x_inner * 32 + y_inner]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = log[0][1]\n",
        "print(\"%s\\t%s\\t%s\" % (\"Operator\".rjust(20), \"Timing\".rjust(20), \"Performance\".rjust(20)))\n",
        "for result in log:\n",
        "    print(\n",
        "        \"%s\\t%s\\t%s\"\n",
        "        % (result[0].rjust(20), str(result[1]).rjust(20), str(baseline / result[1]).rjust(20))\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PriQXp61Mk_m",
        "outputId": "a1b54b18-0fdd-47cc-b4a3-a6315260c49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Operator\t              Timing\t         Performance\n",
            "                none\t        3.9832070625\t                 1.0\n",
            "            blocking\t 0.40209573350000005\t   9.906116207273808\n",
            "       vectorization\t        0.4295229324\t   9.273560878911526\n",
            "    loop permutation\t        0.1920136434\t  20.744396033370617\n",
            "       array packing\t        0.1486536653\t  26.795215943457805\n",
            "       block caching\t        0.1291150856\t  30.850051672815525\n",
            "     parallelization\t        0.2079194518\t  19.157452696304194\n"
          ]
        }
      ]
    }
  ]
}
