{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seongheechoi/education/blob/main/0814_%EA%B3%BC%EC%A0%9C_%EB%B0%A9%EC%A7%84%EC%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef2mMFuh5j4R"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "print(\"Python:\", sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet langchain-core==0.1.23\n",
        "%pip install --quiet langchain==0.1.1\n",
        "%pip install --quiet langchain-google-genai==0.0.6\n",
        "%pip install --quiet -U langchain-community==0.0.20"
      ],
      "metadata": {
        "id": "00Pas_sxL725"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "import os\n",
        "\n",
        "# 무료 API\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = \"여기에 복사 해주세요.\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCi8Lb38YhRl22dFibaXwX1v41hZSOc3pA\"\n",
        "generation_config = {\n",
        "    # TODO: 적절한 값을 적어주세요.\n",
        "    \"temperature\": ,\n",
        "\n",
        "    # TODO: 적절한 값을 적어주세요.\n",
        "    \"top_p\": ,\n",
        "    \"top_k\": ,\n",
        "}\n",
        "\n",
        "model_name = \"gemini-2.5-flash-lite\"\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=model_name,\n",
        "    generation_config=generation_config\n",
        ")"
      ],
      "metadata": {
        "id": "td7bIw-wPA_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 대용량 문서 요약용 라이브러리\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.schema.prompt_template import format_document\n",
        "\n",
        "# 입력 및 출력 과정 중 사용되는 템플릿, Parser (구조화된 형태로 변환해주는 도구)\n",
        "from langchain import PromptTemplate\n",
        "from langchain.schema import StrOutputParser"
      ],
      "metadata": {
        "id": "Fm6IS1jrOnz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URL은 뉴스 기사를 적절히 찾아서 진행해봐도 좋습니다.\n",
        "url = list()\n",
        "url.append(\"https://n.news.naver.com/mnews/article/215/0001220006\")\n",
        "url.append(\"https://n.news.naver.com/mnews/article/009/0005541235\")\n",
        "url.append(\"https://n.news.naver.com/mnews/article/018/0006089218\")\n",
        "url.append(\"https://n.news.naver.com/mnews/article/011/0004520776\")\n",
        "url.append(\"https://n.news.naver.com/mnews/article/009/0005541205\")\n",
        "url.append(\"https://n.news.naver.com/mnews/article/009/0005541194\")\n",
        "url.append(\"https://n.news.naver.com/mnews/article/011/0004520754\")\n",
        "url.append(\"https://n.news.naver.com/mnews/article/011/0004520748\")\n",
        "\n",
        "documents = []\n",
        "for i in range(len(url)):\n",
        "    loader = WebBaseLoader(url[i]) # HTML을 문서로 변환\n",
        "    docs = loader.load()           # 여러 문서들로 분할됨\n",
        "    documents.append(docs)\n",
        "\n",
        "# 문서의 키\n",
        "print(documents[0][0].__dict__.keys())"
      ],
      "metadata": {
        "id": "erQGxhCVOxV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서 내용 추출을 위한 프롬프트 템플릿\n",
        "doc_prompt = PromptTemplate.from_template(\"{page_content}\")\n",
        "\n",
        "# Gemini에 질문하기 위한 프롬프트 템플릿\n",
        "# TODO: 뉴스 기사에서 주식 정보들을 추출하기 위한 프롬프트를 적절히 작성해보세요.\n",
        "llm_prompt_template = \"\"\"\n",
        "<TODO: 뉴스 기사에서 주식 정보들을 추출하기 위한 프롬프트를 적절히 작성해보세요.>:\n",
        "\"{text}\"\n",
        "간결하지만 중요한 주식 정보 요약 내용:\n",
        "\"\"\"[1:-1]\n",
        "\n",
        "llm_prompt = PromptTemplate.from_template(\n",
        "    template=llm_prompt_template\n",
        ")\n",
        "print(llm_prompt)"
      ],
      "metadata": {
        "id": "I94zTpu4PvM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LCEL (LangChain Expression Language)\n",
        "# LangChain 파이프라인 생성\n",
        "stuff_chain = (\n",
        "    {\n",
        "        \"text\": lambda docs: \"\\n\\n\".join(\n",
        "            format_document(doc, doc_prompt) for doc in docs\n",
        "        )\n",
        "    }                    # doc을 doc_prompt에 넣어 page_content 값만을 채택\n",
        "    | llm_prompt         # Gemini를 위한 프롬프트\n",
        "    | llm                # Gemini 응답\n",
        "    | StrOutputParser()  # 결과 반환 파싱\n",
        ")\n",
        "output_batch = stuff_chain.batch([docs, docs])"
      ],
      "metadata": {
        "id": "KNoYsp3JP5xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gemini에 질문하기 위한 프롬프트 템플릿\n",
        "# TODO: 주식 정보를 판단할 수 있는 프롬프트를 작성해보세요.\n",
        "# 어느 주식이 기사에서 유망했는지, 위험한 부분은 무엇인지 그에 따라 어떻게 주식을 투자하면 좋은지 전략적으로 작성해보세요.\n",
        "llm_financial_decision_prompt_template = \"\"\"\n",
        "<TODO: >:\n",
        "\"{text}\"\n",
        "<TODO: 최종 요약 결과 또한 작성해보세요.>:\n",
        "\"\"\"[1:-1]\n",
        "\n",
        "llm_prompt = PromptTemplate.from_template(\n",
        "    template=llm_financial_decision_prompt_template\n",
        ")\n",
        "print(llm_prompt)"
      ],
      "metadata": {
        "id": "MD5P2hxs0uBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LCEL (LangChain Expression Language)\n",
        "# LangChain 파이프라인 생성\n",
        "decision_chain = (\n",
        "    # TODO: output_batch로 text를 생성하고, 최종적으로 주식에 대한 판단에 대한 체인을 연결하여 만드세요.\n",
        ")\n",
        "output = decision_chain.stream(output_batch)\n",
        "print(\"[최종 판단]\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "Ru-DO-mH10nt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}