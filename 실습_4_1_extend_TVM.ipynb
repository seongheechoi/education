{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seongheechoi/education/blob/main/%EC%8B%A4%EC%8A%B5_4_1_extend_TVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TVM 실습자료 4.1**"
      ],
      "metadata": {
        "id": "TTN1jmKjET13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Writing a Customized Pass**"
      ],
      "metadata": {
        "id": "vZZ3YkFEE-UI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4\n",
        "import numpy as np\n",
        "print(np.__version__)\n",
        "!pip list | grep numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "ZV1bsp-ZETVC",
        "outputId": "5bce6ed3-9141-4510-999a-a6bbba76b245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "854f8f2708944c67a1e1b24b14edf356"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n",
            "numpy                                 1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linux/MacOS CPU build only!\n",
        "# See tlcpack.ai for other pre-built binaries including CUDA\n",
        "!python -m pip install --upgrade pip\n",
        "!pip install apache-tvm\n",
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2IKpv6Gj6US",
        "outputId": "b50e8f16-1553-45fb-8723-95f423386519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
            "Requirement already satisfied: apache-tvm in /usr/local/lib/python3.11/dist-packages (0.14.dev273)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (25.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (1.26.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (1.15.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (6.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (4.14.1)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.18.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Writing a Customized Pass**"
      ],
      "metadata": {
        "id": "d2uTjQxkjx0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm\n",
        "from tvm import te\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "h9ZhQ57JjxK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZofknVp1jh0b",
        "outputId": "abbcd984-f260-443d-96f9-85ae3cb46135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(a: T.Buffer((128,), \"float32\"), b: T.Buffer((128,), \"float32\"), c: T.Buffer((128,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for i in range(128):\n",
            "            c[i] = a[i] + b[i]\n"
          ]
        }
      ],
      "source": [
        "n = tvm.tir.const(128, \"int32\")\n",
        "a = te.placeholder((n,), name=\"a\")\n",
        "b = te.placeholder((n,), name=\"b\")\n",
        "c = te.compute((n,), lambda i: a[i] + b[i], name=\"c\")\n",
        "\n",
        "sch = te.create_schedule(c.op)\n",
        "ir = tvm.lower(sch, [a, b, c])\n",
        "print(ir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Writing a Pass**"
      ],
      "metadata": {
        "id": "w-pCDzJIkZAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loops = []\n",
        "\n",
        "def find_width8(op):\n",
        "    \"\"\"Find all the 'tir.For' nodes whose extent can be divided by 8.\"\"\"\n",
        "    if isinstance(op, tvm.tir.For):\n",
        "        if isinstance(op.extent, tvm.tir.IntImm):\n",
        "            if op.extent.value % 8 == 0:\n",
        "                loops.append(op)"
      ],
      "metadata": {
        "id": "u1n4KtZHkA3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IR Transformation**"
      ],
      "metadata": {
        "id": "Xp3vTRb9lT5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize8(op):\n",
        "    \"\"\"Split can vectorize the loops found in `find_width8`.\"\"\"\n",
        "    if op in loops:\n",
        "        extent = op.extent.value\n",
        "        name = op.loop_var.name\n",
        "        lo, li = te.var(name + \".outer\"), te.var(name + \".inner\")\n",
        "        body = tvm.tir.stmt_functor.substitute(op.body, {op.loop_var: lo * 8 + li})\n",
        "        body = tvm.tir.For(li, 0, 8, tvm.tir.ForKind.VECTORIZED, body)\n",
        "        body = tvm.tir.For(lo, 0, extent // 8, tvm.tir.ForKind.SERIAL, body)\n",
        "        return body\n",
        "    return None\n",
        "\n",
        "\n",
        "@tvm.tir.transform.prim_func_pass(opt_level=0)\n",
        "def vectorize(f, mod, ctx):\n",
        "    global loops\n",
        "\n",
        "    tvm.tir.stmt_functor.post_order_visit(f.body, find_width8)\n",
        "\n",
        "    if not loops:\n",
        "        return f\n",
        "\n",
        "    # The last list arugment indicates what kinds of nodes will be transformed.\n",
        "    # Thus, in this case only `For` nodes will call `vectorize8`\n",
        "    return f.with_body(tvm.tir.stmt_functor.ir_transform(f.body, None, vectorize8, [\"tir.For\"]))"
      ],
      "metadata": {
        "id": "w9JLoyQXlVI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Glue to Lowering**"
      ],
      "metadata": {
        "id": "Uwb3-H0flrNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tvm.transform.PassContext(config={\"tir.add_lower_pass\": [(1, vectorize)]}):\n",
        "    print(tvm.lower(sch, [a, b, c]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDF7D0pYlsCt",
        "outputId": "225201d7-0128-49d0-f3f1-be0eec0febe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(a: T.Buffer((128,), \"float32\"), b: T.Buffer((128,), \"float32\"), c: T.Buffer((128,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for i_outer in range(16):\n",
            "            cse_var_1: T.int32 = i_outer * 8\n",
            "            c[cse_var_1:cse_var_1 + 8] = a[cse_var_1:cse_var_1 + 8] + b[cse_var_1:cse_var_1 + 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **How to Use TVM Pass Infra**"
      ],
      "metadata": {
        "id": "jxTAtkbumAB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tvm\n",
        "from tvm import te\n",
        "import tvm.relay as relay"
      ],
      "metadata": {
        "id": "5NoHHKjAmA6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create An Example Relay Program**"
      ],
      "metadata": {
        "id": "U1CxDHo7mD0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def example():\n",
        "    shape = (1, 64, 54, 54)\n",
        "    c_data = np.empty(shape).astype(\"float32\")\n",
        "    c = relay.const(c_data)\n",
        "    weight = relay.var(\"weight\", shape=(64, 64, 3, 3))\n",
        "    x = relay.var(\"x\", relay.TensorType((1, 64, 56, 56), \"float32\"))\n",
        "    conv = relay.nn.conv2d(x, weight)\n",
        "    y = relay.add(c, c)\n",
        "    y = relay.multiply(y, relay.const(2, \"float32\"))\n",
        "    y = relay.add(conv, y)\n",
        "    z = relay.add(y, c)\n",
        "    z1 = relay.add(y, c)\n",
        "    z2 = relay.add(z, z1)\n",
        "    return relay.Function([x, weight], z2)"
      ],
      "metadata": {
        "id": "DUCFeL2JmDMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimize the Program**"
      ],
      "metadata": {
        "id": "1c5-nq40mKSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's first create a relay Module which contains one or multiple Relay\n",
        "# functions for optimization.\n",
        "f = example()\n",
        "mod = tvm.IRModule.from_expr(f)\n",
        "\n",
        "# Now we can apply constant folding on the module.\n",
        "# fold_const here is a callback that doesn't take any parameters.\n",
        "fold_const = relay.transform.FoldConstant()\n",
        "# Then, we can invoke the pass on the given module. Note that the constant\n",
        "# folding pass works at the function-level. That being said, each function in\n",
        "# the module will be applied with the optimization. Users don't need to iterate\n",
        "# through individual functions manually to apply this pass.\n",
        "mod = fold_const(mod)\n",
        "# We can see from the updated program that the constants are folded.\n",
        "print(mod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW_F3_UEmObh",
        "outputId": "f51d9040-c28c-4c8d-f433-134f9fcba07f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-11-567688554.py:3: RuntimeWarning: overflow encountered in cast\n",
            "  c_data = np.empty(shape).astype(\"float32\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %0 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %1 = add(%0, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %2 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %3 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  add(%2, %3) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod = relay.transform.EliminateCommonSubexpr()(mod)\n",
        "print(mod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egfn_1sQmaxQ",
        "outputId": "841e308c-2c77-4056-a324-76b54850b1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %0 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %1 = add(%0, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %2 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod = relay.transform.FuseOps(fuse_opt_level=0)(mod)\n",
        "\n",
        "# We can observe that the optimized module contains functions that only have\n",
        "# a signle primitive op.\n",
        "print(mod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLRO5BhOmh0d",
        "outputId": "3b8bf084-4bf3-41a6-b737-c9555c8f81f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %0 = fn (%p03: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p12: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, Primitive=1) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "    nn.conv2d(%p03, %p12, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32]) -> Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %1 = %0(%x, %weight) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %2 = fn (%p02: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p11: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "    add(%p02, %p11) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -> Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %3 = %2(%1, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %4 = fn (%p01: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p1: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "    add(%p01, %p1) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -> Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %5 = %4(%3, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %6 = fn (%p0: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "    add(%p0, %p0) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 64, 54, 54), float32]) -> Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %6(%5) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use Sequential to Apply a Sequence of Passes**"
      ],
      "metadata": {
        "id": "gNXwRgJAnIbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's execute some passes through :py:class:`tvm.transform.Sequential`\n",
        "f = example()\n",
        "mod = tvm.IRModule.from_expr(f)\n",
        "# Glob the interested passes.\n",
        "seq = tvm.transform.Sequential(\n",
        "    [\n",
        "        relay.transform.FoldConstant(),\n",
        "        relay.transform.EliminateCommonSubexpr(),\n",
        "        relay.transform.FuseOps(fuse_opt_level=2),\n",
        "    ]\n",
        ")\n",
        "mod1 = seq(mod)\n",
        "print(mod1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVOzc0ZvnJWQ",
        "outputId": "105493ff-0261-49f6-e068-80f7bbce09da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %4 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    %3 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    add(%2, %3) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -> Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %4(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tvm.transform.PassContext(opt_level=3):\n",
        "    mod2 = seq(mod)\n",
        "print(mod2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CmcnKmbnO8h",
        "outputId": "f387485d-895a-4f50-f076-ba89ea5a5e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -> Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tvm.transform.PassContext(opt_level=3, disabled_pass=[\"EliminateCommonSubexpr\"]):\n",
        "    mod3 = seq(mod)\n",
        "print(mod3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFgHrMrBnWh_",
        "outputId": "a7228524-af9d-4e5f-f9bd-07a7b6033672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %4 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    %3 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    add(%2, %3) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -> Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %4(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement a Pass Using Python Decorator**"
      ],
      "metadata": {
        "id": "SfFeqP4GngE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@relay.transform.function_pass(opt_level=1)\n",
        "class CustomPipeline:\n",
        "    \"\"\"Simple test function to replace one argument to another.\"\"\"\n",
        "\n",
        "    def __init__(self, multiplier):\n",
        "        self.multiplier = multiplier\n",
        "\n",
        "    # This function can define a pass.\n",
        "    def transform_function(self, func, mod, ctx):\n",
        "        obj = self\n",
        "\n",
        "        class ReplaceConstant(tvm.relay.ExprMutator):\n",
        "            def visit_constant(self, c):\n",
        "                return relay.multiply(obj.multiplier, c)\n",
        "\n",
        "        return ReplaceConstant().visit(func)\n",
        "\n",
        "\n",
        "f = example()\n",
        "mod = tvm.IRModule.from_expr(f)\n",
        "custom_pass = CustomPipeline(multiplier=relay.const(3, \"float32\"))\n",
        "assert custom_pass.info.name == \"CustomPipeline\"\n",
        "mod3 = custom_pass(mod)\n",
        "print(mod3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPV5TW37nYDn",
        "outputId": "31558e9b-782f-4e73-e581-ee5055f948d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %0 = multiply(3f /* ty=float32 */, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %1 = add(%0, %0) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %2 = multiply(3f /* ty=float32 */, 2f /* ty=float32 */) /* ty=float32 */;\n",
            "  %3 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %4 = multiply(%1, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %5 = add(%3, %4) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %6 = add(%5, %0) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %7 = add(%5, %0) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  add(%6, %7) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Debug a Pass**"
      ],
      "metadata": {
        "id": "_VPpMepAooiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = example()\n",
        "mod = tvm.IRModule.from_expr(f)\n",
        "seq = tvm.transform.Sequential(\n",
        "    [\n",
        "        relay.transform.FoldConstant(),\n",
        "        tvm.transform.PrintIR(),\n",
        "        relay.transform.EliminateCommonSubexpr(),\n",
        "        relay.transform.FuseOps(),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "rDTGLGEEng6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.instrument.pass_instrument\n",
        "class PrintIR:\n",
        "    \"\"\"Print the name of the pass, the IR, only before passes execute.\"\"\"\n",
        "\n",
        "    def run_before_pass(self, mod, info):\n",
        "        print(\"Running pass: {}\", info)\n",
        "        print(mod)\n",
        "\n",
        "\n",
        "with tvm.transform.PassContext(opt_level=3, instruments=[PrintIR()]):\n",
        "    with tvm.target.Target(\"llvm\"):\n",
        "        # Perform the optimizations.\n",
        "        mod = seq(mod)\n",
        "print(mod)\n",
        "\n",
        "print(\"done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_7XZyG4otIj",
        "outputId": "6f062d64-5fd1-4716-9267-e4247af02ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running pass: {} The meta data of the pass - pass name: sequential, opt_level: 0, required passes: []\n",
            "\n",
            "def @main(%x: Tensor[(1, 64, 56, 56), float32], %weight: Tensor[(64, 64, 3, 3), float32]) {\n",
            "  %0 = add(meta[relay.Constant][0], meta[relay.Constant][0]);\n",
            "  %1 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0]);\n",
            "  %2 = multiply(%0, 2f);\n",
            "  %3 = add(%1, %2);\n",
            "  %4 = add(%3, meta[relay.Constant][0]);\n",
            "  %5 = add(%3, meta[relay.Constant][0]);\n",
            "  add(%4, %5)\n",
            "}\n",
            "\n",
            "\n",
            "Running pass: {} The meta data of the pass - pass name: FoldConstant, opt_level: 2, required passes: []\n",
            "\n",
            "def @main(%x: Tensor[(1, 64, 56, 56), float32], %weight: Tensor[(64, 64, 3, 3), float32]) {\n",
            "  %0 = add(meta[relay.Constant][0], meta[relay.Constant][0]);\n",
            "  %1 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0]);\n",
            "  %2 = multiply(%0, 2f);\n",
            "  %3 = add(%1, %2);\n",
            "  %4 = add(%3, meta[relay.Constant][0]);\n",
            "  %5 = add(%3, meta[relay.Constant][0]);\n",
            "  add(%4, %5)\n",
            "}\n",
            "\n",
            "\n",
            "Running pass: {} The meta data of the pass - pass name: InferType, opt_level: 0, required passes: []\n",
            "\n",
            "def @main(%x: Tensor[(1, 64, 56, 56), float32], %weight: Tensor[(64, 64, 3, 3), float32]) {\n",
            "  %0 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0]);\n",
            "  %1 = add(%0, meta[relay.Constant][0]);\n",
            "  %2 = add(%1, meta[relay.Constant][1]);\n",
            "  %3 = add(%1, meta[relay.Constant][1]);\n",
            "  add(%2, %3)\n",
            "}\n",
            "\n",
            "\n",
            "Running pass: {} The meta data of the pass - pass name: PrintIR, opt_level: 0, required passes: []\n",
            "\n",
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %0 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %1 = add(%0, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %2 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %3 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  add(%2, %3) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n",
            "Running pass: {} The meta data of the pass - pass name: InferType, opt_level: 0, required passes: []\n",
            "\n",
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %0 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %1 = add(%0, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %2 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %3 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  add(%2, %3) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n",
            "Running pass: {} The meta data of the pass - pass name: EliminateCommonSubexpr, opt_level: 3, required passes: [\n",
            "InferType, ]\n",
            "\n",
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %0 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %1 = add(%0, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %2 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %3 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  add(%2, %3) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n",
            "Running pass: {} The meta data of the pass - pass name: InferType, opt_level: 0, required passes: []\n",
            "\n",
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %0 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %1 = add(%0, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %2 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n",
            "Running pass: {} The meta data of the pass - pass name: InferType, opt_level: 0, required passes: []\n",
            "\n",
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %0 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %1 = add(%0, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %2 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n",
            "Running pass: {} The meta data of the pass - pass name: FuseOps, opt_level: 0, required passes: [\n",
            "InferType, ]\n",
            "\n",
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %0 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %1 = add(%0, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %2 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "  add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n",
            "Running pass: {} The meta data of the pass - pass name: InferType, opt_level: 0, required passes: []\n",
            "\n",
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32], %p1: Tensor[(64, 64, 3, 3), float32], %p2: Tensor[(1, 64, 54, 54), float32], %p3: Tensor[(1, 64, 54, 54), float32], Primitive=1) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0]);\n",
            "    %1 = add(%0, %p2);\n",
            "    %2 = add(%1, %p3);\n",
            "    add(%2, %2)\n",
            "  };\n",
            "  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */)\n",
            "}\n",
            "\n",
            "\n",
            "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "  %3 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -> Tensor[(1, 64, 54, 54), float32] {\n",
            "    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
            "    add(%2, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -> Tensor[(1, 64, 54, 54), float32] */;\n",
            "  %3(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
            "}\n",
            "\n",
            "\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **How to Use TVM Pass Instrument**"
      ],
      "metadata": {
        "id": "7MixcjbPo7iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm\n",
        "import tvm.relay as relay\n",
        "from tvm.relay.testing import resnet\n",
        "from tvm.contrib.download import download_testdata\n",
        "from tvm.relay.build_module import bind_params_by_name\n",
        "from tvm.ir.instrument import (\n",
        "    PassTimingInstrument,\n",
        "    pass_instrument,\n",
        ")"
      ],
      "metadata": {
        "id": "uksdHe62o864"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create An Example Relay Program**"
      ],
      "metadata": {
        "id": "nOhHKcucpBEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "num_of_image_class = 1000\n",
        "image_shape = (3, 224, 224)\n",
        "output_shape = (batch_size, num_of_image_class)\n",
        "relay_mod, relay_params = resnet.get_workload(num_layers=18, batch_size=1, image_shape=image_shape)\n",
        "print(\"Printing the IR module...\")\n",
        "print(relay_mod.astext(show_meta_data=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5h83RispArg",
        "outputId": "7348a704-8cb2-4a45-ce0c-56fe20afeb1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing the IR module...\n",
            "#[version = \"0.0.5\"]\n",
            "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %bn_data_gamma: Tensor[(3), float32] /* ty=Tensor[(3), float32] */, %bn_data_beta: Tensor[(3), float32] /* ty=Tensor[(3), float32] */, %bn_data_moving_mean: Tensor[(3), float32] /* ty=Tensor[(3), float32] */, %bn_data_moving_var: Tensor[(3), float32] /* ty=Tensor[(3), float32] */, %conv0_weight: Tensor[(64, 3, 7, 7), float32] /* ty=Tensor[(64, 3, 7, 7), float32] */, %bn0_gamma: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %bn0_beta: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %bn0_moving_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %bn0_moving_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit1_bn1_gamma: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit1_bn1_beta: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit1_bn1_moving_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit1_bn1_moving_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit1_conv1_weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %stage1_unit1_bn2_gamma: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit1_bn2_beta: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit1_bn2_moving_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit1_bn2_moving_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit1_conv2_weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %stage1_unit1_sc_weight: Tensor[(64, 64, 1, 1), float32] /* ty=Tensor[(64, 64, 1, 1), float32] */, %stage1_unit2_bn1_gamma: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit2_bn1_beta: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit2_bn1_moving_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit2_bn1_moving_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit2_conv1_weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %stage1_unit2_bn2_gamma: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit2_bn2_beta: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit2_bn2_moving_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit2_bn2_moving_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage1_unit2_conv2_weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %stage2_unit1_bn1_gamma: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage2_unit1_bn1_beta: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage2_unit1_bn1_moving_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage2_unit1_bn1_moving_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %stage2_unit1_conv1_weight: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %stage2_unit1_bn2_gamma: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage2_unit1_bn2_beta: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage2_unit1_bn2_moving_mean: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage2_unit1_bn2_moving_var: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage2_unit1_conv2_weight: Tensor[(128, 128, 3, 3), float32] /* ty=Tensor[(128, 128, 3, 3), float32] */, %stage2_unit1_sc_weight: Tensor[(128, 64, 1, 1), float32] /* ty=Tensor[(128, 64, 1, 1), float32] */, %stage2_unit2_bn1_gamma: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage2_unit2_bn1_beta: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage2_unit2_bn1_moving_mean: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage2_unit2_bn1_moving_var: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage2_unit2_conv1_weight: Tensor[(128, 128, 3, 3), float32] /* ty=Tensor[(128, 128, 3, 3), float32] */, %stage2_unit2_bn2_gamma: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage2_unit2_bn2_beta: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage2_unit2_bn2_moving_mean: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage2_unit2_bn2_moving_var: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage2_unit2_conv2_weight: Tensor[(128, 128, 3, 3), float32] /* ty=Tensor[(128, 128, 3, 3), float32] */, %stage3_unit1_bn1_gamma: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage3_unit1_bn1_beta: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage3_unit1_bn1_moving_mean: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage3_unit1_bn1_moving_var: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %stage3_unit1_conv1_weight: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %stage3_unit1_bn2_gamma: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage3_unit1_bn2_beta: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage3_unit1_bn2_moving_mean: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage3_unit1_bn2_moving_var: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage3_unit1_conv2_weight: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %stage3_unit1_sc_weight: Tensor[(256, 128, 1, 1), float32] /* ty=Tensor[(256, 128, 1, 1), float32] */, %stage3_unit2_bn1_gamma: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage3_unit2_bn1_beta: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage3_unit2_bn1_moving_mean: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage3_unit2_bn1_moving_var: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage3_unit2_conv1_weight: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %stage3_unit2_bn2_gamma: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage3_unit2_bn2_beta: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage3_unit2_bn2_moving_mean: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage3_unit2_bn2_moving_var: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage3_unit2_conv2_weight: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %stage4_unit1_bn1_gamma: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage4_unit1_bn1_beta: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage4_unit1_bn1_moving_mean: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage4_unit1_bn1_moving_var: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %stage4_unit1_conv1_weight: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %stage4_unit1_bn2_gamma: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %stage4_unit1_bn2_beta: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %stage4_unit1_bn2_moving_mean: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %stage4_unit1_bn2_moving_var: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %stage4_unit1_conv2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %stage4_unit1_sc_weight: Tensor[(512, 256, 1, 1), float32] /* ty=Tensor[(512, 256, 1, 1), float32] */, %stage4_unit2_bn1_gamma: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %stage4_unit2_bn1_beta: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %stage4_unit2_bn1_moving_mean: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %stage4_unit2_bn1_moving_var: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %stage4_unit2_conv1_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %stage4_unit2_bn2_gamma: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %stage4_unit2_bn2_beta: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %stage4_unit2_bn2_moving_mean: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %stage4_unit2_bn2_moving_var: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %stage4_unit2_conv2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %bn1_gamma: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %bn1_beta: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %bn1_moving_mean: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %bn1_moving_var: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %fc1_weight: Tensor[(1000, 512), float32] /* ty=Tensor[(1000, 512), float32] */, %fc1_bias: Tensor[(1000), float32] /* ty=Tensor[(1000), float32] */) -> Tensor[(1, 1000), float32] {\n",
            "  %0 = nn.batch_norm(%data, %bn_data_gamma, %bn_data_beta, %bn_data_moving_mean, %bn_data_moving_var, epsilon=2e-05f, scale=False) /* ty=(Tensor[(1, 3, 224, 224), float32], Tensor[(3), float32], Tensor[(3), float32]) */;\n",
            "  %1 = %0.0 /* ty=Tensor[(1, 3, 224, 224), float32] */;\n",
            "  %2 = nn.conv2d(%1, %conv0_weight, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
            "  %3 = nn.batch_norm(%2, %bn0_gamma, %bn0_beta, %bn0_moving_mean, %bn0_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 64, 112, 112), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
            "  %4 = %3.0 /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
            "  %5 = nn.relu(%4) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
            "  %6 = nn.max_pool2d(%5, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %7 = nn.batch_norm(%6, %stage1_unit1_bn1_gamma, %stage1_unit1_bn1_beta, %stage1_unit1_bn1_moving_mean, %stage1_unit1_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
            "  %8 = %7.0 /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %9 = nn.relu(%8) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %10 = nn.conv2d(%9, %stage1_unit1_conv1_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %11 = nn.batch_norm(%10, %stage1_unit1_bn2_gamma, %stage1_unit1_bn2_beta, %stage1_unit1_bn2_moving_mean, %stage1_unit1_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
            "  %12 = %11.0 /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %13 = nn.relu(%12) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %14 = nn.conv2d(%13, %stage1_unit1_conv2_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %15 = nn.conv2d(%9, %stage1_unit1_sc_weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %16 = add(%14, %15) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %17 = nn.batch_norm(%16, %stage1_unit2_bn1_gamma, %stage1_unit2_bn1_beta, %stage1_unit2_bn1_moving_mean, %stage1_unit2_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
            "  %18 = %17.0 /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %19 = nn.relu(%18) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %20 = nn.conv2d(%19, %stage1_unit2_conv1_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %21 = nn.batch_norm(%20, %stage1_unit2_bn2_gamma, %stage1_unit2_bn2_beta, %stage1_unit2_bn2_moving_mean, %stage1_unit2_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
            "  %22 = %21.0 /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %23 = nn.relu(%22) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %24 = nn.conv2d(%23, %stage1_unit2_conv2_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %25 = add(%24, %16) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %26 = nn.batch_norm(%25, %stage2_unit1_bn1_gamma, %stage2_unit1_bn1_beta, %stage2_unit1_bn1_moving_mean, %stage2_unit1_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
            "  %27 = %26.0 /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %28 = nn.relu(%27) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
            "  %29 = nn.conv2d(%28, %stage2_unit1_conv1_weight, strides=[2, 2], padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %30 = nn.batch_norm(%29, %stage2_unit1_bn2_gamma, %stage2_unit1_bn2_beta, %stage2_unit1_bn2_moving_mean, %stage2_unit1_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128), float32], Tensor[(128), float32]) */;\n",
            "  %31 = %30.0 /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %32 = nn.relu(%31) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %33 = nn.conv2d(%32, %stage2_unit1_conv2_weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %34 = nn.conv2d(%28, %stage2_unit1_sc_weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %35 = add(%33, %34) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %36 = nn.batch_norm(%35, %stage2_unit2_bn1_gamma, %stage2_unit2_bn1_beta, %stage2_unit2_bn1_moving_mean, %stage2_unit2_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128), float32], Tensor[(128), float32]) */;\n",
            "  %37 = %36.0 /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %38 = nn.relu(%37) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %39 = nn.conv2d(%38, %stage2_unit2_conv1_weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %40 = nn.batch_norm(%39, %stage2_unit2_bn2_gamma, %stage2_unit2_bn2_beta, %stage2_unit2_bn2_moving_mean, %stage2_unit2_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128), float32], Tensor[(128), float32]) */;\n",
            "  %41 = %40.0 /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %42 = nn.relu(%41) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %43 = nn.conv2d(%42, %stage2_unit2_conv2_weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %44 = add(%43, %35) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %45 = nn.batch_norm(%44, %stage3_unit1_bn1_gamma, %stage3_unit1_bn1_beta, %stage3_unit1_bn1_moving_mean, %stage3_unit1_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128), float32], Tensor[(128), float32]) */;\n",
            "  %46 = %45.0 /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %47 = nn.relu(%46) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
            "  %48 = nn.conv2d(%47, %stage3_unit1_conv1_weight, strides=[2, 2], padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %49 = nn.batch_norm(%48, %stage3_unit1_bn2_gamma, %stage3_unit1_bn2_beta, %stage3_unit1_bn2_moving_mean, %stage3_unit1_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256), float32], Tensor[(256), float32]) */;\n",
            "  %50 = %49.0 /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %51 = nn.relu(%50) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %52 = nn.conv2d(%51, %stage3_unit1_conv2_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %53 = nn.conv2d(%47, %stage3_unit1_sc_weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %54 = add(%52, %53) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %55 = nn.batch_norm(%54, %stage3_unit2_bn1_gamma, %stage3_unit2_bn1_beta, %stage3_unit2_bn1_moving_mean, %stage3_unit2_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256), float32], Tensor[(256), float32]) */;\n",
            "  %56 = %55.0 /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %57 = nn.relu(%56) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %58 = nn.conv2d(%57, %stage3_unit2_conv1_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %59 = nn.batch_norm(%58, %stage3_unit2_bn2_gamma, %stage3_unit2_bn2_beta, %stage3_unit2_bn2_moving_mean, %stage3_unit2_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256), float32], Tensor[(256), float32]) */;\n",
            "  %60 = %59.0 /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %61 = nn.relu(%60) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %62 = nn.conv2d(%61, %stage3_unit2_conv2_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %63 = add(%62, %54) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %64 = nn.batch_norm(%63, %stage4_unit1_bn1_gamma, %stage4_unit1_bn1_beta, %stage4_unit1_bn1_moving_mean, %stage4_unit1_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256), float32], Tensor[(256), float32]) */;\n",
            "  %65 = %64.0 /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %66 = nn.relu(%65) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
            "  %67 = nn.conv2d(%66, %stage4_unit1_conv1_weight, strides=[2, 2], padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %68 = nn.batch_norm(%67, %stage4_unit1_bn2_gamma, %stage4_unit1_bn2_beta, %stage4_unit1_bn2_moving_mean, %stage4_unit1_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512), float32], Tensor[(512), float32]) */;\n",
            "  %69 = %68.0 /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %70 = nn.relu(%69) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %71 = nn.conv2d(%70, %stage4_unit1_conv2_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %72 = nn.conv2d(%66, %stage4_unit1_sc_weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %73 = add(%71, %72) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %74 = nn.batch_norm(%73, %stage4_unit2_bn1_gamma, %stage4_unit2_bn1_beta, %stage4_unit2_bn1_moving_mean, %stage4_unit2_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512), float32], Tensor[(512), float32]) */;\n",
            "  %75 = %74.0 /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %76 = nn.relu(%75) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %77 = nn.conv2d(%76, %stage4_unit2_conv1_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %78 = nn.batch_norm(%77, %stage4_unit2_bn2_gamma, %stage4_unit2_bn2_beta, %stage4_unit2_bn2_moving_mean, %stage4_unit2_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512), float32], Tensor[(512), float32]) */;\n",
            "  %79 = %78.0 /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %80 = nn.relu(%79) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %81 = nn.conv2d(%80, %stage4_unit2_conv2_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %82 = add(%81, %73) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %83 = nn.batch_norm(%82, %bn1_gamma, %bn1_beta, %bn1_moving_mean, %bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512), float32], Tensor[(512), float32]) */;\n",
            "  %84 = %83.0 /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %85 = nn.relu(%84) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %86 = nn.global_avg_pool2d(%85) /* ty=Tensor[(1, 512, 1, 1), float32] */;\n",
            "  %87 = nn.batch_flatten(%86) /* ty=Tensor[(1, 512), float32] */;\n",
            "  %88 = nn.dense(%87, %fc1_weight, units=1000) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %89 = nn.bias_add(%88, %fc1_bias, axis=-1) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  nn.softmax(%89) /* ty=Tensor[(1, 1000), float32] */\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create PassContext With Instruments**"
      ],
      "metadata": {
        "id": "zafqMIeRpcUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timing_inst = PassTimingInstrument()\n",
        "with tvm.transform.PassContext(instruments=[timing_inst]):\n",
        "    relay_mod = relay.transform.InferType()(relay_mod)\n",
        "    relay_mod = relay.transform.FoldScaleAxis()(relay_mod)\n",
        "    # before exiting the context, get profile results.\n",
        "    profiles = timing_inst.render()\n",
        "print(\"Printing results of timing profile...\")\n",
        "print(profiles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmklaaxEpc_L",
        "outputId": "87623167-60a9-4447-de68-5568c90931ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing results of timing profile...\n",
            "InferType: 50479us [50479us] (51.47%; 51.47%)\n",
            "FoldScaleAxis: 47604us [76us] (48.53%; 48.53%)\n",
            "\tFoldConstant: 47528us [2868us] (48.46%; 99.84%)\n",
            "\t\tInferType: 44660us [44660us] (45.53%; 93.97%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use Current PassContext With Instruments**"
      ],
      "metadata": {
        "id": "FW2AVuanqJ7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur_pass_ctx = tvm.transform.PassContext.current()\n",
        "cur_pass_ctx.override_instruments([timing_inst])\n",
        "relay_mod = relay.transform.InferType()(relay_mod)\n",
        "relay_mod = relay.transform.FoldScaleAxis()(relay_mod)\n",
        "profiles = timing_inst.render()\n",
        "print(\"Printing results of timing profile...\")\n",
        "print(profiles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLaUvb5sqLEv",
        "outputId": "789fcfa2-8eea-4973-f35b-4a0fbf36aea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing results of timing profile...\n",
            "InferType: 50464us [50464us] (53.17%; 53.17%)\n",
            "FoldScaleAxis: 44441us [18us] (46.83%; 46.83%)\n",
            "\tFoldConstant: 44423us [2505us] (46.81%; 99.96%)\n",
            "\t\tInferType: 41918us [41918us] (44.17%; 94.36%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cur_pass_ctx.override_instruments([])\n",
        "# Uncomment the call to .render() to see a warning like:\n",
        "# Warning: no passes have been profiled, did you enable pass profiling?\n",
        "# profiles = timing_inst.render()"
      ],
      "metadata": {
        "id": "Bhil7ofwqOg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Customized Instrument Class**"
      ],
      "metadata": {
        "id": "pJrlO2jFqQ1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@pass_instrument\n",
        "class RelayCallNodeDiffer:\n",
        "    def __init__(self):\n",
        "        self._op_diff = []\n",
        "        # Passes can be nested.\n",
        "        # Use stack to make sure we get correct before/after pairs.\n",
        "        self._op_cnt_before_stack = []\n",
        "\n",
        "    def enter_pass_ctx(self):\n",
        "        self._op_diff = []\n",
        "        self._op_cnt_before_stack = []\n",
        "\n",
        "    def exit_pass_ctx(self):\n",
        "        assert len(self._op_cnt_before_stack) == 0, \"The stack is not empty. Something wrong.\"\n",
        "\n",
        "    def run_before_pass(self, mod, info):\n",
        "        self._op_cnt_before_stack.append((info.name, self._count_nodes(mod)))\n",
        "\n",
        "    def run_after_pass(self, mod, info):\n",
        "        # Pop out the latest recorded pass.\n",
        "        name_before, op_to_cnt_before = self._op_cnt_before_stack.pop()\n",
        "        assert name_before == info.name, \"name_before: {}, info.name: {} doesn't match\".format(\n",
        "            name_before, info.name\n",
        "        )\n",
        "        cur_depth = len(self._op_cnt_before_stack)\n",
        "        op_to_cnt_after = self._count_nodes(mod)\n",
        "        op_diff = self._diff(op_to_cnt_after, op_to_cnt_before)\n",
        "        # only record passes causing differences.\n",
        "        if op_diff:\n",
        "            self._op_diff.append((cur_depth, info.name, op_diff))\n",
        "\n",
        "    def get_pass_to_op_diff(self):\n",
        "        \"\"\"\n",
        "        return [\n",
        "          (depth, pass_name, {op_name: diff_num, ...}), ...\n",
        "        ]\n",
        "        \"\"\"\n",
        "        return self._op_diff\n",
        "\n",
        "    @staticmethod\n",
        "    def _count_nodes(mod):\n",
        "        \"\"\"Count the number of occurrences of each operator in the module\"\"\"\n",
        "        ret = {}\n",
        "\n",
        "        def visit(node):\n",
        "            if isinstance(node, relay.expr.Call):\n",
        "                if hasattr(node.op, \"name\"):\n",
        "                    op_name = node.op.name\n",
        "                else:\n",
        "                    # Some CallNode may not have 'name' such as relay.Function\n",
        "                    return\n",
        "                ret[op_name] = ret.get(op_name, 0) + 1\n",
        "\n",
        "        relay.analysis.post_order_visit(mod[\"main\"], visit)\n",
        "        return ret\n",
        "\n",
        "    @staticmethod\n",
        "    def _diff(d_after, d_before):\n",
        "        \"\"\"Calculate the difference of two dictionary along their keys.\n",
        "        The result is values in d_after minus values in d_before.\n",
        "        \"\"\"\n",
        "        ret = {}\n",
        "        key_after, key_before = set(d_after), set(d_before)\n",
        "        for k in key_before & key_after:\n",
        "            tmp = d_after[k] - d_before[k]\n",
        "            if tmp:\n",
        "                ret[k] = d_after[k] - d_before[k]\n",
        "        for k in key_after - key_before:\n",
        "            ret[k] = d_after[k]\n",
        "        for k in key_before - key_after:\n",
        "            ret[k] = -d_before[k]\n",
        "        return ret"
      ],
      "metadata": {
        "id": "Ptx5IpeIqR0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply Passes and Multiple Instrument Classes**"
      ],
      "metadata": {
        "id": "2JHlu-lfqaYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_node_inst = RelayCallNodeDiffer()\n",
        "desired_layouts = {\n",
        "    \"nn.conv2d\": [\"NHWC\", \"HWIO\"],\n",
        "}\n",
        "pass_seq = tvm.transform.Sequential(\n",
        "    [\n",
        "        relay.transform.FoldConstant(),\n",
        "        relay.transform.ConvertLayout(desired_layouts),\n",
        "        relay.transform.FoldConstant(),\n",
        "    ]\n",
        ")\n",
        "relay_mod[\"main\"] = bind_params_by_name(relay_mod[\"main\"], relay_params)\n",
        "# timing_inst is put after call_node_inst.\n",
        "# So the execution time of ``call_node.inst.run_after_pass()`` is also counted.\n",
        "with tvm.transform.PassContext(opt_level=3, instruments=[call_node_inst, timing_inst]):\n",
        "    relay_mod = pass_seq(relay_mod)\n",
        "    profiles = timing_inst.render()\n",
        "# Uncomment the next line to see timing-profile results.\n",
        "# print(profiles)"
      ],
      "metadata": {
        "id": "taiK5Y4Hqcbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "print(\"Printing the change in number of occurrences of each operator caused by each pass...\")\n",
        "pprint(call_node_inst.get_pass_to_op_diff())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oiKzCYGqeFa",
        "outputId": "50c0db03-95ce-42cc-e9e5-62da621742a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing the change in number of occurrences of each operator caused by each pass...\n",
            "[(1, 'CanonicalizeOps', {'add': 1, 'nn.bias_add': -1}),\n",
            " (1, 'ConvertLayout', {'expand_dims': 1, 'layout_transform': 23}),\n",
            " (1, 'FoldConstant', {'expand_dims': -1, 'layout_transform': -21}),\n",
            " (0, 'sequential', {'add': 1, 'layout_transform': 2, 'nn.bias_add': -1})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exception Handling**"
      ],
      "metadata": {
        "id": "7xDozJPyqcJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PassExampleBase:\n",
        "    def __init__(self, name):\n",
        "        self._name = name\n",
        "\n",
        "    def enter_pass_ctx(self):\n",
        "        print(self._name, \"enter_pass_ctx\")\n",
        "\n",
        "    def exit_pass_ctx(self):\n",
        "        print(self._name, \"exit_pass_ctx\")\n",
        "\n",
        "    def should_run(self, mod, info):\n",
        "        print(self._name, \"should_run\")\n",
        "        return True\n",
        "\n",
        "    def run_before_pass(self, mod, pass_info):\n",
        "        print(self._name, \"run_before_pass\")\n",
        "\n",
        "    def run_after_pass(self, mod, pass_info):\n",
        "        print(self._name, \"run_after_pass\")\n",
        "\n",
        "\n",
        "@pass_instrument\n",
        "class PassFine(PassExampleBase):\n",
        "    pass\n",
        "\n",
        "\n",
        "@pass_instrument\n",
        "class PassBadEnterCtx(PassExampleBase):\n",
        "    def enter_pass_ctx(self):\n",
        "        print(self._name, \"bad enter_pass_ctx!!!\")\n",
        "        raise ValueError(\"{} bad enter_pass_ctx\".format(self._name))\n",
        "\n",
        "\n",
        "@pass_instrument\n",
        "class PassBadExitCtx(PassExampleBase):\n",
        "    def exit_pass_ctx(self):\n",
        "        print(self._name, \"bad exit_pass_ctx!!!\")\n",
        "        raise ValueError(\"{} bad exit_pass_ctx\".format(self._name))"
      ],
      "metadata": {
        "id": "dSMtxJ77qlgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_ctx = tvm.transform.PassContext(\n",
        "    instruments=[\n",
        "        PassFine(\"PassFine_0\"),\n",
        "        PassBadEnterCtx(\"PassBadEnterCtx\"),\n",
        "        PassFine(\"PassFine_1\"),\n",
        "    ]\n",
        ")\n",
        "try:\n",
        "    with demo_ctx:\n",
        "        relay_mod = relay.transform.InferType()(relay_mod)\n",
        "except ValueError as ex:\n",
        "    print(\"Catching\", str(ex).split(\"\\n\")[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhHwxat6qo0l",
        "outputId": "7221f8f9-44b9-4b8e-9f59-161d0fa74e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassFine_0 enter_pass_ctx\n",
            "PassBadEnterCtx bad enter_pass_ctx!!!\n",
            "PassFine_0 exit_pass_ctx\n",
            "Catching PassBadEnterCtx bad enter_pass_ctx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_ctx.override_instruments([])  # no PassFine_0 exit_pass_ctx printed....etc"
      ],
      "metadata": {
        "id": "8VXv3P-9qshu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_ctx = tvm.transform.PassContext(\n",
        "    instruments=[\n",
        "        PassFine(\"PassFine_0\"),\n",
        "        PassBadExitCtx(\"PassBadExitCtx\"),\n",
        "        PassFine(\"PassFine_1\"),\n",
        "    ]\n",
        ")\n",
        "try:\n",
        "    # PassFine_1 execute enter_pass_ctx, but not exit_pass_ctx.\n",
        "    with demo_ctx:\n",
        "        relay_mod = relay.transform.InferType()(relay_mod)\n",
        "except ValueError as ex:\n",
        "    print(\"Catching\", str(ex).split(\"\\n\")[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4vuhIiEquQW",
        "outputId": "97a3b0c9-e7ac-44a1-9fa5-1c3fe7e41957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassFine_0 enter_pass_ctx\n",
            "PassBadExitCtx enter_pass_ctx\n",
            "PassFine_1 enter_pass_ctx\n",
            "PassFine_0 should_run\n",
            "PassBadExitCtx should_run\n",
            "PassFine_1 should_run\n",
            "PassFine_0 run_before_pass\n",
            "PassBadExitCtx run_before_pass\n",
            "PassFine_1 run_before_pass\n",
            "PassFine_0 run_after_pass\n",
            "PassBadExitCtx run_after_pass\n",
            "PassFine_1 run_after_pass\n",
            "PassFine_0 exit_pass_ctx\n",
            "PassBadExitCtx bad exit_pass_ctx!!!\n",
            "Catching PassBadExitCtx bad exit_pass_ctx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@pass_instrument\n",
        "class PassBadRunBefore(PassExampleBase):\n",
        "    def run_before_pass(self, mod, pass_info):\n",
        "        print(self._name, \"bad run_before_pass!!!\")\n",
        "        raise ValueError(\"{} bad run_before_pass\".format(self._name))\n",
        "\n",
        "\n",
        "demo_ctx = tvm.transform.PassContext(\n",
        "    instruments=[\n",
        "        PassFine(\"PassFine_0\"),\n",
        "        PassBadRunBefore(\"PassBadRunBefore\"),\n",
        "        PassFine(\"PassFine_1\"),\n",
        "    ]\n",
        ")\n",
        "try:\n",
        "    # All exit_pass_ctx are called.\n",
        "    with demo_ctx:\n",
        "        relay_mod = relay.transform.InferType()(relay_mod)\n",
        "except ValueError as ex:\n",
        "    print(\"Catching\", str(ex).split(\"\\n\")[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hozGNGSTq0vM",
        "outputId": "106b5142-57f1-4662-d895-7331f74db0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassFine_0 enter_pass_ctx\n",
            "PassBadRunBefore enter_pass_ctx\n",
            "PassFine_1 enter_pass_ctx\n",
            "PassFine_0 should_run\n",
            "PassBadRunBefore should_run\n",
            "PassFine_1 should_run\n",
            "PassFine_0 run_before_pass\n",
            "PassBadRunBefore bad run_before_pass!!!\n",
            "PassFine_0 exit_pass_ctx\n",
            "PassBadRunBefore exit_pass_ctx\n",
            "PassFine_1 exit_pass_ctx\n",
            "Catching PassBadRunBefore bad run_before_pass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_ctx.override_instruments([])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M72xEnLmq7h_",
        "outputId": "0638daf9-9bb6-4626-ca9c-3887a1847b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassFine_0 exit_pass_ctx\n",
            "PassBadRunBefore exit_pass_ctx\n",
            "PassFine_1 exit_pass_ctx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cur_pass_ctx = tvm.transform.PassContext.current()\n",
        "cur_pass_ctx.override_instruments(\n",
        "    [\n",
        "        PassFine(\"PassFine_0\"),\n",
        "        PassBadRunBefore(\"PassBadRunBefore\"),\n",
        "        PassFine(\"PassFine_1\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G16bcx6fq90v",
        "outputId": "0108721a-f922-44fb-ef48-82ecc5f58de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassFine_0 enter_pass_ctx\n",
            "PassBadRunBefore enter_pass_ctx\n",
            "PassFine_1 enter_pass_ctx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # No ``exit_pass_ctx`` got executed.\n",
        "    relay_mod = relay.transform.InferType()(relay_mod)\n",
        "except ValueError as ex:\n",
        "    print(\"Catching\", str(ex).split(\"\\n\")[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoUab0pDq8gn",
        "outputId": "739f0116-52f1-4bf0-8622-206705320921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassFine_0 should_run\n",
            "PassBadRunBefore should_run\n",
            "PassFine_1 should_run\n",
            "PassFine_0 run_before_pass\n",
            "PassBadRunBefore bad run_before_pass!!!\n",
            "Catching PassBadRunBefore bad run_before_pass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cur_pass_ctx.override_instruments([])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itqwui7ArDrd",
        "outputId": "198d2811-28e4-4922-d0ff-4b903071f155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassFine_0 exit_pass_ctx\n",
            "PassBadRunBefore exit_pass_ctx\n",
            "PassFine_1 exit_pass_ctx\n"
          ]
        }
      ]
    }
  ]
}