{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seongheechoi/education/blob/main/%EC%8B%A4%EC%8A%B5_2_2_work_with_tensor_expression_and_schedules.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TVM 실습자료 2.2: Working with Tensor Expression and Schedules**"
      ],
      "metadata": {
        "id": "2Rfg8twuQTkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4\n",
        "import numpy as np\n",
        "print(np.__version__)\n",
        "!pip list | grep numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "hHs_8upfxJ89",
        "outputId": "05b47300-19a9-4195-b1b8-8c0c19e72993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "f44fe449b822443a9e615bab189bc97a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n",
            "numpy                                 1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVzkLugrQRGh",
        "outputId": "c018e457-ff23-4fe7-e70e-b10a8b0248ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.1.1\n",
            "Collecting apache-tvm\n",
            "  Downloading apache_tvm-0.14.dev273-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (25.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (1.26.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (1.15.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (6.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (4.14.1)\n",
            "Downloading apache_tvm-0.14.dev273-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: apache-tvm\n",
            "Successfully installed apache-tvm-0.14.dev273\n"
          ]
        }
      ],
      "source": [
        "# Linux/MacOS CPU build only!\n",
        "# See tlcpack.ai for other pre-built binaries including CUDA\n",
        "!python -m pip install --upgrade pip\n",
        "!pip install apache-tvm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Schedule Primitives in TVM**"
      ],
      "metadata": {
        "id": "0Mhk4n_VRVW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, print_function\n",
        "\n",
        "\n",
        "import tvm\n",
        "from tvm import te\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "v6nUFkp-QaxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# declare some variables for use later\n",
        "n = te.var(\"n\")\n",
        "m = te.var(\"m\")\n",
        "\n",
        "# declare a matrix element-wise multiply\n",
        "A = te.placeholder((m, n), name=\"A\")\n",
        "B = te.placeholder((m, n), name=\"B\")\n",
        "C = te.compute((m, n), lambda i, j: A[i, j] * B[i, j], name=\"C\")\n",
        "\n",
        "s = te.create_schedule([C.op])"
      ],
      "metadata": {
        "id": "LH5LSc3wRaeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lower will transform the computation from definition to the real\n",
        "# callable function. With argument `simple_mode=True`, it will\n",
        "# return you a readable C like statement, we use it here to print the\n",
        "# schedule result.\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59C3vFy-Rfxz",
        "outputId": "772f60c7-764c-4ee8-c133-66a9cb88bf0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        m, n = T.int32(), T.int32()\n",
            "        A_1 = T.match_buffer(A, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        C_1 = T.match_buffer(C, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        for i, j in T.grid(m, n):\n",
            "            C_2 = T.Buffer((C_1.strides[0] * m,), data=C_1.data, buffer_type=\"auto\")\n",
            "            A_2 = T.Buffer((A_1.strides[0] * m,), data=A_1.data, buffer_type=\"auto\")\n",
            "            B_2 = T.Buffer((B_1.strides[0] * m,), data=B_1.data, buffer_type=\"auto\")\n",
            "            C_2[i * C_1.strides[0] + j * C_1.strides[1]] = A_2[i * A_1.strides[0] + j * A_1.strides[1]] * B_2[i * B_1.strides[0] + j * B_1.strides[1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**split**"
      ],
      "metadata": {
        "id": "KY8txQZ8i7N0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = te.placeholder((m,), name=\"A\")\n",
        "B = te.compute((m,), lambda i: A[i] * 2, name=\"B\")\n",
        "\n",
        "s = te.create_schedule(B.op)\n",
        "xo, xi = s[B].split(B.op.axis[0], factor=32)\n",
        "print(tvm.lower(s, [A, B], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpgzia5CRn51",
        "outputId": "c6e77a20-929e-4ed3-9700-1a528db5b173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        m = T.int32()\n",
            "        A_1 = T.match_buffer(A, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        for i_outer, i_inner in T.grid((m + 31) // 32, 32):\n",
            "            if T.likely(i_outer * 32 + i_inner < m):\n",
            "                B_2 = T.Buffer((B_1.strides[0] * m,), data=B_1.data, buffer_type=\"auto\")\n",
            "                A_2 = T.Buffer((A_1.strides[0] * m,), data=A_1.data, buffer_type=\"auto\")\n",
            "                cse_var_1: T.int32 = i_outer * 32 + i_inner\n",
            "                B_2[cse_var_1 * B_1.strides[0]] = A_2[cse_var_1 * A_1.strides[0]] * T.float32(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = te.placeholder((m,), name=\"A\")\n",
        "B = te.compute((m,), lambda i: A[i], name=\"B\")\n",
        "\n",
        "s = te.create_schedule(B.op)\n",
        "bx, tx = s[B].split(B.op.axis[0], nparts=32)\n",
        "print(tvm.lower(s, [A, B], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNCGwTM1R_Mx",
        "outputId": "3b10ba0c-5c8f-480c-feec-eb33cab30a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        m = T.int32()\n",
            "        A_1 = T.match_buffer(A, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        for i_outer, i_inner in T.grid(32, (m + 31) // 32):\n",
            "            if T.likely(i_inner + i_outer * ((m + 31) // 32) < m):\n",
            "                B_2 = T.Buffer((B_1.strides[0] * m,), data=B_1.data, buffer_type=\"auto\")\n",
            "                A_2 = T.Buffer((A_1.strides[0] * m,), data=A_1.data, buffer_type=\"auto\")\n",
            "                B_2[(i_inner + i_outer * ((m + 31) // 32)) * B_1.strides[0]] = A_2[(i_inner + i_outer * ((m + 31) // 32)) * A_1.strides[0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tile**"
      ],
      "metadata": {
        "id": "X38DHVovi_xW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = te.placeholder((m, n), name=\"A\")\n",
        "B = te.compute((m, n), lambda i, j: A[i, j], name=\"B\")\n",
        "\n",
        "s = te.create_schedule(B.op)\n",
        "xo, yo, xi, yi = s[B].tile(B.op.axis[0], B.op.axis[1], x_factor=10, y_factor=5)\n",
        "print(tvm.lower(s, [A, B], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxB9k5ptSaPo",
        "outputId": "07131075-246a-4426-95fa-692f59aedeba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        m, n = T.int32(), T.int32()\n",
            "        A_1 = T.match_buffer(A, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        for i_outer, j_outer, i_inner in T.grid((m + 9) // 10, (n + 4) // 5, 10):\n",
            "            if T.likely(i_outer * 10 + i_inner < m):\n",
            "                for j_inner in range(5):\n",
            "                    if T.likely(j_outer * 5 + j_inner < n):\n",
            "                        cse_var_2: T.int32 = j_outer * 5 + j_inner\n",
            "                        cse_var_1: T.int32 = i_outer * 10 + i_inner\n",
            "                        B_2 = T.Buffer((B_1.strides[0] * m,), data=B_1.data, buffer_type=\"auto\")\n",
            "                        A_2 = T.Buffer((A_1.strides[0] * m,), data=A_1.data, buffer_type=\"auto\")\n",
            "                        B_2[cse_var_1 * B_1.strides[0] + cse_var_2 * B_1.strides[1]] = A_2[cse_var_1 * A_1.strides[0] + cse_var_2 * A_1.strides[1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**fuse**"
      ],
      "metadata": {
        "id": "9PKuCV4vpDcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = te.placeholder((m, n), name=\"A\")\n",
        "B = te.compute((m, n), lambda i, j: A[i, j], name=\"B\")\n",
        "\n",
        "s = te.create_schedule(B.op)\n",
        "# tile to four axes first: (i.outer, j.outer, i.inner, j.inner)\n",
        "xo, yo, xi, yi = s[B].tile(B.op.axis[0], B.op.axis[1], x_factor=10, y_factor=5)\n",
        "# then fuse (i.inner, j.inner) into one axis: (i.inner.j.inner.fused)\n",
        "fused = s[B].fuse(xi, yi)\n",
        "print(tvm.lower(s, [A, B], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEf1MyMDSjUb",
        "outputId": "6747d234-9075-4878-ccff-c66debe73cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        m, n = T.int32(), T.int32()\n",
            "        A_1 = T.match_buffer(A, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        for i_outer, j_outer, i_inner_j_inner_fused in T.grid((m + 9) // 10, (n + 4) // 5, 50):\n",
            "            if T.likely(i_outer * 10 + i_inner_j_inner_fused // 5 < m):\n",
            "                if T.likely(j_outer * 5 + i_inner_j_inner_fused % 5 < n):\n",
            "                    cse_var_2: T.int32 = j_outer * 5 + i_inner_j_inner_fused % 5\n",
            "                    cse_var_1: T.int32 = i_outer * 10 + i_inner_j_inner_fused // 5\n",
            "                    B_2 = T.Buffer((B_1.strides[0] * m,), data=B_1.data, buffer_type=\"auto\")\n",
            "                    A_2 = T.Buffer((A_1.strides[0] * m,), data=A_1.data, buffer_type=\"auto\")\n",
            "                    B_2[cse_var_1 * B_1.strides[0] + cse_var_2 * B_1.strides[1]] = A_2[cse_var_1 * A_1.strides[0] + cse_var_2 * A_1.strides[1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tvm.lower(s, [A, B], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIl_hJhuSlcs",
        "outputId": "2ec01409-91be-4c16-e70a-7344718ac633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@main = primfn(A_1: handle, B_1: handle) -> ()\n",
            "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
            "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [m: int32, n: int32], [stride: int32, stride_1: int32], type=\"auto\"),\n",
            "             B: Buffer(B_2: Pointer(float32), float32, [m, n], [stride_2: int32, stride_3: int32], type=\"auto\")}\n",
            "  buffer_map = {A_1: A, B_1: B} {\n",
            "  for (i.outer: int32, 0, floordiv((m + 9), 10)) {\n",
            "    for (j.outer: int32, 0, floordiv((n + 4), 5)) {\n",
            "      for (i.inner.j.inner.fused: int32, 0, 50) {\n",
            "        if @tir.likely((((i.outer*10) + floordiv(i.inner.j.inner.fused, 5)) < m), dtype=bool) {\n",
            "          if @tir.likely((((j.outer*5) + floormod(i.inner.j.inner.fused, 5)) < n), dtype=bool) {\n",
            "            let cse_var_2: int32 = ((j.outer*5) + floormod(i.inner.j.inner.fused, 5))\n",
            "            let cse_var_1: int32 = ((i.outer*10) + floordiv(i.inner.j.inner.fused, 5))\n",
            "            B_3: Buffer(B_2, float32, [(stride_2*m)], [], type=\"auto\")[((cse_var_1*stride_2) + (cse_var_2*stride_3))] = A_3: Buffer(A_2, float32, [(stride*m)], [], type=\"auto\")[((cse_var_1*stride) + (cse_var_2*stride_1))]\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**reorder**"
      ],
      "metadata": {
        "id": "xKeB7FrLpKeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = te.placeholder((m, n), name=\"A\")\n",
        "B = te.compute((m, n), lambda i, j: A[i, j], name=\"B\")\n",
        "\n",
        "s = te.create_schedule(B.op)\n",
        "# tile to four axes first: (i.outer, j.outer, i.inner, j.inner)\n",
        "xo, yo, xi, yi = s[B].tile(B.op.axis[0], B.op.axis[1], x_factor=10, y_factor=5)\n",
        "# then reorder the axes: (i.inner, j.outer, i.outer, j.inner)\n",
        "s[B].reorder(xi, yo, xo, yi)\n",
        "print(tvm.lower(s, [A, B], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2ArOIZHSusb",
        "outputId": "6840b337-55c9-481e-95ac-60bf9240d6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        m, n = T.int32(), T.int32()\n",
            "        A_1 = T.match_buffer(A, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        for i_inner, j_outer, i_outer in T.grid(10, (n + 4) // 5, (m + 9) // 10):\n",
            "            if T.likely(i_outer * 10 + i_inner < m):\n",
            "                for j_inner in range(5):\n",
            "                    if T.likely(j_outer * 5 + j_inner < n):\n",
            "                        cse_var_2: T.int32 = j_outer * 5 + j_inner\n",
            "                        cse_var_1: T.int32 = i_outer * 10 + i_inner\n",
            "                        B_2 = T.Buffer((B_1.strides[0] * m,), data=B_1.data, buffer_type=\"auto\")\n",
            "                        A_2 = T.Buffer((A_1.strides[0] * m,), data=A_1.data, buffer_type=\"auto\")\n",
            "                        B_2[cse_var_1 * B_1.strides[0] + cse_var_2 * B_1.strides[1]] = A_2[cse_var_1 * A_1.strides[0] + cse_var_2 * A_1.strides[1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bind**"
      ],
      "metadata": {
        "id": "7X1DqxwkpM1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = te.placeholder((n,), name=\"A\")\n",
        "B = te.compute(A.shape, lambda i: A[i] * 2, name=\"B\")\n",
        "\n",
        "s = te.create_schedule(B.op)\n",
        "bx, tx = s[B].split(B.op.axis[0], factor=64)\n",
        "s[B].bind(bx, te.thread_axis(\"blockIdx.x\"))\n",
        "s[B].bind(tx, te.thread_axis(\"threadIdx.x\"))\n",
        "print(tvm.lower(s, [A, B], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvnNKcLsS3F7",
        "outputId": "56636d7a-3832-4723-9f1f-1e5c0c33ad49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        n = T.int32()\n",
            "        A_1 = T.match_buffer(A, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", (n + 63) // 64)\n",
            "        threadIdx_x = T.launch_thread(\"threadIdx.x\", 64)\n",
            "        if T.likely(blockIdx_x * 64 + threadIdx_x < n):\n",
            "            B_2 = T.Buffer((B_1.strides[0] * n,), data=B_1.data, buffer_type=\"auto\")\n",
            "            A_2 = T.Buffer((A_1.strides[0] * n,), data=A_1.data, buffer_type=\"auto\")\n",
            "            B_2[(blockIdx_x * 64 + threadIdx_x) * B_1.strides[0]] = A_2[(blockIdx_x * 64 + threadIdx_x) * A_1.strides[0]] * T.float32(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**compute_at**"
      ],
      "metadata": {
        "id": "Wcz9YxuJpTYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = te.placeholder((m,), name=\"A\")\n",
        "B = te.compute((m,), lambda i: A[i] + 1, name=\"B\")\n",
        "C = te.compute((m,), lambda i: B[i] * 2, name=\"C\")\n",
        "\n",
        "s = te.create_schedule(C.op)\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh7snaM8TH8A",
        "outputId": "c6e2364d-e697-4b2c-b9ee-8dd3e7ffde7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        m = T.int32()\n",
            "        A_1 = T.match_buffer(A, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        C_1 = T.match_buffer(C, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        B_2 = T.Buffer((B_1.strides[0] * m,), data=B_1.data, buffer_type=\"auto\")\n",
            "        for i in range(m):\n",
            "            A_2 = T.Buffer((A_1.strides[0] * m,), data=A_1.data, buffer_type=\"auto\")\n",
            "            B_2[i * B_1.strides[0]] = A_2[i * A_1.strides[0]] + T.float32(1)\n",
            "        for i in range(m):\n",
            "            C_2 = T.Buffer((C_1.strides[0] * m,), data=C_1.data, buffer_type=\"auto\")\n",
            "            C_2[i * C_1.strides[0]] = B_2[i * B_1.strides[0]] * T.float32(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = te.placeholder((m,), name=\"A\")\n",
        "B = te.compute((m,), lambda i: A[i] + 1, name=\"B\")\n",
        "C = te.compute((m,), lambda i: B[i] * 2, name=\"C\")\n",
        "\n",
        "s = te.create_schedule(C.op)\n",
        "s[B].compute_at(s[C], C.op.axis[0])\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY9Y9R_1TJjB",
        "outputId": "cd6c2c64-5c4b-4153-c951-9fa202accff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        m = T.int32()\n",
            "        A_1 = T.match_buffer(A, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        C_1 = T.match_buffer(C, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        for i in range(m):\n",
            "            B_2 = T.Buffer((B_1.strides[0] * m,), data=B_1.data, buffer_type=\"auto\")\n",
            "            A_2 = T.Buffer((A_1.strides[0] * m,), data=A_1.data, buffer_type=\"auto\")\n",
            "            B_2[i * B_1.strides[0]] = A_2[i * A_1.strides[0]] + T.float32(1)\n",
            "            C_2 = T.Buffer((C_1.strides[0] * m,), data=C_1.data, buffer_type=\"auto\")\n",
            "            C_2[i * C_1.strides[0]] = B_2[i * B_1.strides[0]] * T.float32(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**compute_inline**"
      ],
      "metadata": {
        "id": "sP7ZoANKpZja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = te.placeholder((m,), name=\"A\")\n",
        "B = te.compute((m,), lambda i: A[i] + 1, name=\"B\")\n",
        "C = te.compute((m,), lambda i: B[i] * 2, name=\"C\")\n",
        "\n",
        "s = te.create_schedule(C.op)\n",
        "s[B].compute_inline()\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tVXYhpCTPb8",
        "outputId": "c6c5ead9-8a04-47a7-fb39-ef6d56870dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        m = T.int32()\n",
            "        A_1 = T.match_buffer(A, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        C_1 = T.match_buffer(C, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        for i in range(m):\n",
            "            C_2 = T.Buffer((C_1.strides[0] * m,), data=C_1.data, buffer_type=\"auto\")\n",
            "            A_2 = T.Buffer((A_1.strides[0] * m,), data=A_1.data, buffer_type=\"auto\")\n",
            "            C_2[i * C_1.strides[0]] = (A_2[i * A_1.strides[0]] + T.float32(1)) * T.float32(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**compute_root**"
      ],
      "metadata": {
        "id": "YzGl67vypdVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = te.placeholder((m,), name=\"A\")\n",
        "B = te.compute((m,), lambda i: A[i] + 1, name=\"B\")\n",
        "C = te.compute((m,), lambda i: B[i] * 2, name=\"C\")\n",
        "\n",
        "s = te.create_schedule(C.op)\n",
        "s[B].compute_at(s[C], C.op.axis[0])\n",
        "s[B].compute_root()\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQkbIcjtTQaU",
        "outputId": "68c109ae-ce6d-420e-e904-409ab9af5a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        m = T.int32()\n",
            "        A_1 = T.match_buffer(A, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        C_1 = T.match_buffer(C, (m,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        B_2 = T.Buffer((B_1.strides[0] * m,), data=B_1.data, buffer_type=\"auto\")\n",
            "        for i in range(m):\n",
            "            A_2 = T.Buffer((A_1.strides[0] * m,), data=A_1.data, buffer_type=\"auto\")\n",
            "            B_2[i * B_1.strides[0]] = A_2[i * A_1.strides[0]] + T.float32(1)\n",
            "        for i in range(m):\n",
            "            C_2 = T.Buffer((C_1.strides[0] * m,), data=C_1.data, buffer_type=\"auto\")\n",
            "            C_2[i * C_1.strides[0]] = B_2[i * B_1.strides[0]] * T.float32(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reduction**"
      ],
      "metadata": {
        "id": "XeyHVOjKTc8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, print_function\n",
        "\n",
        "\n",
        "import tvm\n",
        "import tvm.testing\n",
        "from tvm import te\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ZTJHDTKIpqBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Describe Sum of Rows**"
      ],
      "metadata": {
        "id": "ZfxaD7YApt-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = te.var(\"n\")\n",
        "m = te.var(\"m\")\n",
        "A = te.placeholder((n, m), name=\"A\")\n",
        "k = te.reduce_axis((0, m), \"k\")\n",
        "B = te.compute((n,), lambda i: te.sum(A[i, k], axis=k), name=\"B\")"
      ],
      "metadata": {
        "id": "S5juz9vSprk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schedule the Reduction**"
      ],
      "metadata": {
        "id": "VgbVmm06pyS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = te.create_schedule(B.op)\n",
        "print(tvm.lower(s, [A, B], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkhObbRzpz4W",
        "outputId": "82ad17f3-716d-4107-c91f-5d9d57b81a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        n, m = T.int32(), T.int32()\n",
            "        A_1 = T.match_buffer(A, (n, m), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        for i in range(n):\n",
            "            B_2 = T.Buffer((B_1.strides[0] * n,), data=B_1.data, buffer_type=\"auto\")\n",
            "            B_2[i * B_1.strides[0]] = T.float32(0)\n",
            "            for k in range(m):\n",
            "                A_2 = T.Buffer((A_1.strides[0] * n,), data=A_1.data, buffer_type=\"auto\")\n",
            "                B_2[i * B_1.strides[0]] = B_2[i * B_1.strides[0]] + A_2[i * A_1.strides[0] + k * A_1.strides[1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ko, ki = s[B].split(B.op.reduce_axis[0], factor=16)\n",
        "xo, xi = s[B].split(B.op.axis[0], factor=32)\n",
        "print(tvm.lower(s, [A, B], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GNk6P-Up3QH",
        "outputId": "cf5b9c57-360d-4601-bb5e-a886328ed268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        n, m = T.int32(), T.int32()\n",
            "        A_1 = T.match_buffer(A, (n, m), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        for i_outer, i_inner in T.grid((n + 31) // 32, 32):\n",
            "            B_2 = T.Buffer((B_1.strides[0] * n,), data=B_1.data, buffer_type=\"auto\")\n",
            "            if T.likely(i_outer * 32 + i_inner < n):\n",
            "                B_2[(i_outer * 32 + i_inner) * B_1.strides[0]] = T.float32(0)\n",
            "            if T.likely(i_outer * 32 + i_inner < n):\n",
            "                for k_outer, k_inner in T.grid((m + 15) // 16, 16):\n",
            "                    if T.likely(k_outer * 16 + k_inner < m):\n",
            "                        A_2 = T.Buffer((A_1.strides[0] * n,), data=A_1.data, buffer_type=\"auto\")\n",
            "                        cse_var_1: T.int32 = i_outer * 32 + i_inner\n",
            "                        B_2[cse_var_1 * B_1.strides[0]] = B_2[cse_var_1 * B_1.strides[0]] + A_2[cse_var_1 * A_1.strides[0] + (k_outer * 16 + k_inner) * A_1.strides[1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reduction Factoring and Parallelization**"
      ],
      "metadata": {
        "id": "Nl-POUxPqK27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = te.create_schedule(B.op)\n",
        "ko, ki = s[B].split(B.op.reduce_axis[0], factor=16)\n",
        "BF = s.rfactor(B, ki)\n",
        "print(tvm.lower(s, [A, B], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILLf6Q1bqMB6",
        "outputId": "bc68ae8c-36f3-4384-e743-2a1b80d4b195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.handle, B: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        n, m = T.int32(), T.int32()\n",
            "        A_1 = T.match_buffer(A, (n, m), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        B_1 = T.match_buffer(B, (n,), strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        B_rf = T.allocate([n * 16], \"float32\", \"global\")\n",
            "        B_rf_1 = T.Buffer((16 * n,), data=B_rf)\n",
            "        for k_inner, i in T.grid(16, n):\n",
            "            B_rf_1[k_inner * n + i] = T.float32(0)\n",
            "            for k_outer in range((m + 15) // 16):\n",
            "                if T.likely(k_outer * 16 + k_inner < m):\n",
            "                    A_2 = T.Buffer((A_1.strides[0] * n,), data=A_1.data, buffer_type=\"auto\")\n",
            "                    B_rf_1[k_inner * n + i] = B_rf_1[k_inner * n + i] + A_2[i * A_1.strides[0] + (k_outer * 16 + k_inner) * A_1.strides[1]]\n",
            "        for ax0 in range(n):\n",
            "            B_2 = T.Buffer((B_1.strides[0] * n,), data=B_1.data, buffer_type=\"auto\")\n",
            "            B_2[ax0 * B_1.strides[0]] = T.float32(0)\n",
            "            for k_inner_v in range(16):\n",
            "                B_2[ax0 * B_1.strides[0]] = B_2[ax0 * B_1.strides[0]] + B_rf_1[k_inner_v * n + ax0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(s[B].op.body)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4242T_7qSM2",
        "outputId": "663b0f9b-40e0-491a-e8d5-2e4768baad78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[T.reduce(T.comm_reducer(lambda x, y: x + y, [T.float32(0)]), source=[B.rf[k_inner_v, ax0]], init=[], axis=[T.iter_var(k_inner_v, T.Range(0, 16), \"CommReduce\", \"\")], condition=T.bool(True), value_index=0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Describe Convolution via 2D Reduction**"
      ],
      "metadata": {
        "id": "KRlruegHqXW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = te.var(\"n\")\n",
        "Input = te.placeholder((n, n), name=\"Input\")\n",
        "Filter = te.placeholder((3, 3), name=\"Filter\")\n",
        "di = te.reduce_axis((0, 3), name=\"di\")\n",
        "dj = te.reduce_axis((0, 3), name=\"dj\")\n",
        "Output = te.compute(\n",
        "    (n - 2, n - 2),\n",
        "    lambda i, j: te.sum(Input[i + di, j + dj] * Filter[di, dj], axis=[di, dj]),\n",
        "    name=\"Output\",\n",
        ")\n",
        "s = te.create_schedule(Output.op)\n",
        "print(tvm.lower(s, [Input, Filter, Output], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqWXbmA6qYmR",
        "outputId": "db3818f5-42e3-491b-a764-9de21ea24202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(Input: T.handle, Filter: T.Buffer((3, 3), \"float32\"), Output: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        n = T.int32()\n",
            "        Input_1 = T.match_buffer(Input, (n, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        Output_1 = T.match_buffer(Output, (n - 2, n - 2))\n",
            "        for i, j in T.grid(n - 2, n - 2):\n",
            "            Output_2 = T.Buffer(((n - 2) * (n - 2),), data=Output_1.data)\n",
            "            Output_2[i * (n - 2) + j] = T.float32(0)\n",
            "            for di, dj in T.grid(3, 3):\n",
            "                Input_2 = T.Buffer((Input_1.strides[0] * n,), data=Input_1.data, buffer_type=\"auto\")\n",
            "                Filter_1 = T.Buffer((9,), data=Filter.data)\n",
            "                Output_2[i * (n - 2) + j] = Output_2[i * (n - 2) + j] + Input_2[(i + di) * Input_1.strides[0] + (j + dj) * Input_1.strides[1]] * Filter_1[di * 3 + dj]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define General Commutative Reduction Operation**"
      ],
      "metadata": {
        "id": "t1-qzSPDqkvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = te.var(\"n\")\n",
        "m = te.var(\"m\")\n",
        "product = te.comm_reducer(lambda x, y: x * y, lambda t: tvm.tir.const(1, dtype=t), name=\"product\")\n",
        "A = te.placeholder((n, m), name=\"A\")\n",
        "k = te.reduce_axis((0, m), name=\"k\")\n",
        "B = te.compute((n,), lambda i: product(A[i, k], axis=k), name=\"B\")"
      ],
      "metadata": {
        "id": "bqeWL0UdqlxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Intrinsics and Math Functions**"
      ],
      "metadata": {
        "id": "e3p0W-VEq3ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, print_function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tvm\n",
        "from tvm import te\n",
        "from tvm.ir import register_op_attr, register_intrin_lowering"
      ],
      "metadata": {
        "id": "wqZl8Dyiq5HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Direct Declare Extern Math Call**"
      ],
      "metadata": {
        "id": "t71tLHaoq8SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = te.var(\"n\")\n",
        "A = te.placeholder((n,), name=\"A\")\n",
        "B = te.compute(A.shape, lambda i: tvm.tir.call_pure_extern(\"float32\", \"__expf\", A[i]), name=\"B\")\n",
        "s = te.create_schedule(B.op)\n",
        "num_thread = 64\n",
        "bx, tx = s[B].split(B.op.axis[0], factor=num_thread)\n",
        "s[B].bind(bx, te.thread_axis(\"blockIdx.x\"))\n",
        "s[B].bind(tx, te.thread_axis(\"threadIdx.x\"))\n",
        "f = tvm.build(s, [A, B], \"cuda\", name=\"myexp\")\n",
        "print(f.imported_modules[0].get_source())"
      ],
      "metadata": {
        "id": "5dciD3IFrK25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unified Intrinsic Call**"
      ],
      "metadata": {
        "id": "-Nj8YPCvrayb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = te.var(\"n\")\n",
        "A = te.placeholder((n,), name=\"A\")\n",
        "B = te.compute(A.shape, lambda i: te.exp(A[i]), name=\"B\")\n",
        "s = te.create_schedule(B.op)\n",
        "num_thread = 64\n",
        "bx, tx = s[B].split(B.op.axis[0], factor=num_thread)\n",
        "s[B].bind(bx, te.thread_axis(\"blockIdx.x\"))\n",
        "s[B].bind(tx, te.thread_axis(\"threadIdx.x\"))\n",
        "fcuda = tvm.build(s, [A, B], \"cuda\", name=\"myexp\")\n",
        "print(fcuda.imported_modules[0].get_source())"
      ],
      "metadata": {
        "id": "uHnLRN_drN3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fopencl = tvm.build(s, [A, B], \"opencl\", name=\"myexp\")\n",
        "print(fopencl.imported_modules[0].get_source())"
      ],
      "metadata": {
        "id": "GYt74ifyrdBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intrinsic Lowering Rule**"
      ],
      "metadata": {
        "id": "t30Qp3XcrnoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_cuda_math_rule(op):\n",
        "    \"\"\"Customized CUDA intrinsic lowering rule\"\"\"\n",
        "    assert isinstance(op, tvm.tir.Call)\n",
        "    name = op.op.name\n",
        "    assert name.startswith(\"tir.\")\n",
        "    dispatch_name = name[4:]\n",
        "    if op.dtype == \"float32\":\n",
        "        # call float function\n",
        "        return tvm.tir.call_pure_extern(\"float32\", \"%sf\" % dispatch_name, op.args[0])\n",
        "    elif op.dtype == \"float64\":\n",
        "        # call double function\n",
        "        return tvm.tir.call_pure_extern(\"float32\", dispatch_name, op.args[0])\n",
        "    else:\n",
        "        # cannot do translation, return self.\n",
        "        return op\n",
        "\n",
        "\n",
        "register_intrin_lowering(\"tir.exp\", target=\"cuda\", f=my_cuda_math_rule, level=99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "rpJYzF4arlKJ",
        "outputId": "465d8cb6-a2c6-4126-9bb5-a8b1f6684420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.my_cuda_math_rule(op)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>my_cuda_math_rule</b><br/>def my_cuda_math_rule(op)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-27-d36f056fa57e&gt;</a>Customized CUDA intrinsic lowering rule</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fcuda = tvm.build(s, [A, B], \"cuda\", name=\"myexp\")\n",
        "print(fcuda.imported_modules[0].get_source())"
      ],
      "metadata": {
        "id": "dyOJieW7rxaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add Your Own Intrinsic**"
      ],
      "metadata": {
        "id": "tlPPYEmIr6F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mylog(x):\n",
        "    \"\"\"customized log intrinsic function\"\"\"\n",
        "    return tvm.tir.call_intrin(x.dtype, \"tir.mylog\", x)\n",
        "\n",
        "\n",
        "def my_cuda_mylog_rule(op):\n",
        "    \"\"\"CUDA lowering rule for log\"\"\"\n",
        "    if op.dtype == \"float32\":\n",
        "        return tvm.tir.call_pure_extern(\"float32\", \"logf\", op.args[0])\n",
        "    elif op.dtype == \"float64\":\n",
        "        return tvm.tir.call_pure_extern(\"float64\", \"log\", op.args[0])\n",
        "    else:\n",
        "        return op\n",
        "\n",
        "\n",
        "# new op registration is triggered by registering an attribute of the op\n",
        "register_op_attr(\"tir.mylog\", \"TCallEffectKind\", tvm.tir.CallEffectKind.Pure)\n",
        "register_intrin_lowering(\"tir.mylog\", target=\"cuda\", f=my_cuda_mylog_rule, level=99)\n",
        "\n",
        "n = te.var(\"n\")\n",
        "A = te.placeholder((n,), name=\"A\")\n",
        "B = te.compute(A.shape, lambda i: mylog(A[i]), name=\"B\")\n",
        "s = te.create_schedule(B.op)\n",
        "num_thread = 64\n",
        "bx, tx = s[B].split(B.op.axis[0], factor=num_thread)\n",
        "s[B].bind(bx, te.thread_axis(\"blockIdx.x\"))\n",
        "s[B].bind(tx, te.thread_axis(\"threadIdx.x\"))\n",
        "fcuda = tvm.build(s, [A, B], \"cuda\", name=\"mylog\")\n",
        "print(fcuda.imported_modules[0].get_source())"
      ],
      "metadata": {
        "id": "qdZibpP2r7IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Use Tensorize to Leverage Hardware Intrinsics**"
      ],
      "metadata": {
        "id": "zCx25QJ_sBq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, print_function\n",
        "\n",
        "\n",
        "import tvm\n",
        "from tvm import te\n",
        "import tvm.testing\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "55K0LyLYsDAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Matrix Multiplication**"
      ],
      "metadata": {
        "id": "wqfpcS3gsFPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, M, L = 1024, 512, 64\n",
        "A = te.placeholder((N, L), name=\"A\")\n",
        "B = te.placeholder((M, L), name=\"B\")\n",
        "k = te.reduce_axis((0, L), name=\"k\")\n",
        "C = te.compute((N, M), lambda i, j: te.sum(A[i, k] * B[j, k], axis=k), name=\"C\")\n",
        "s = te.create_schedule(C.op)\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOQ5nvMtsGRu",
        "outputId": "4113eab5-3e72-42be-f264-88130a9a2dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 64), \"float32\"), B: T.Buffer((512, 64), \"float32\"), C: T.Buffer((1024, 512), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for i, j in T.grid(1024, 512):\n",
            "            C_1 = T.Buffer((524288,), data=C.data)\n",
            "            C_1[i * 512 + j] = T.float32(0)\n",
            "            for k in range(64):\n",
            "                cse_var_1: T.int32 = i * 512 + j\n",
            "                A_1 = T.Buffer((65536,), data=A.data)\n",
            "                B_1 = T.Buffer((32768,), data=B.data)\n",
            "                C_1[cse_var_1] = C_1[cse_var_1] + A_1[i * 64 + k] * B_1[j * 64 + k]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schedule the Matmul**"
      ],
      "metadata": {
        "id": "nb2CtRmrsPCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "factor = 16\n",
        "x, y = C.op.axis\n",
        "(z,) = C.op.reduce_axis\n",
        "yo, yi = s[C].split(y, factor=factor)\n",
        "s[C].reorder(x, yo, yi, z)\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stW6HR17sOm2",
        "outputId": "6339042b-51d2-4b2d-de51-06f7369ec1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 64), \"float32\"), B: T.Buffer((512, 64), \"float32\"), C: T.Buffer((1024, 512), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for i, j_outer, j_inner in T.grid(1024, 32, 16):\n",
            "            C_1 = T.Buffer((524288,), data=C.data)\n",
            "            C_1[i * 512 + j_outer * 16 + j_inner] = T.float32(0)\n",
            "            for k in range(64):\n",
            "                cse_var_1: T.int32 = i * 512 + j_outer * 16 + j_inner\n",
            "                A_1 = T.Buffer((65536,), data=A.data)\n",
            "                B_1 = T.Buffer((32768,), data=B.data)\n",
            "                C_1[cse_var_1] = C_1[cse_var_1] + A_1[i * 64 + k] * B_1[j_outer * 1024 + j_inner * 64 + k]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define GEMV Tensorization Intrinsic**"
      ],
      "metadata": {
        "id": "Dd-SsX3csbPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def intrin_gemv(m, l):\n",
        "    a = te.placeholder((l,), name=\"a\")\n",
        "    b = te.placeholder((m, l), name=\"b\")\n",
        "    k = te.reduce_axis((0, l), name=\"k\")\n",
        "    c = te.compute((m,), lambda i: te.sum(a[k] * b[i, k], axis=k), name=\"c\")\n",
        "    Ab = tvm.tir.decl_buffer(a.shape, a.dtype, name=\"A\", offset_factor=1, strides=[1])\n",
        "    Bb = tvm.tir.decl_buffer(b.shape, b.dtype, name=\"B\", offset_factor=1, strides=[te.var(\"s1\"), 1])\n",
        "    Cb = tvm.tir.decl_buffer(c.shape, c.dtype, name=\"C\", offset_factor=1, strides=[1])\n",
        "\n",
        "    def intrin_func(ins, outs):\n",
        "        ib = tvm.tir.ir_builder.create()\n",
        "        aa, bb = ins\n",
        "        cc = outs[0]\n",
        "        ib.emit(\n",
        "            tvm.tir.call_extern(\n",
        "                \"int32\",\n",
        "                \"gemv_update\",\n",
        "                cc.access_ptr(\"w\"),\n",
        "                aa.access_ptr(\"r\"),\n",
        "                bb.access_ptr(\"r\"),\n",
        "                m,\n",
        "                l,\n",
        "                bb.strides[0],\n",
        "            )\n",
        "        )\n",
        "        return ib.get()\n",
        "\n",
        "    return te.decl_tensor_intrin(c.op, intrin_func, binds={a: Ab, b: Bb, c: Cb})"
      ],
      "metadata": {
        "id": "KPQChzOuscWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemv = intrin_gemv(factor, L)\n",
        "s[C].tensorize(yi, gemv)\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCJrjgDluQBG",
        "outputId": "daa7e6b1-78a8-4a97-ea3c-48340c1c53d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 64), \"float32\"), B: T.Buffer((512, 64), \"float32\"), C: T.Buffer((1024, 512), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for i, j_outer in T.grid(1024, 32):\n",
            "            T.call_extern(\"int32\", \"gemv_update\", T.tvm_access_ptr(T.type_annotation(\"float32\"), C.data, i * 512 + j_outer * 16, 16, 2), T.tvm_access_ptr(T.type_annotation(\"float32\"), A.data, i * 64, 64, 1), T.tvm_access_ptr(T.type_annotation(\"float32\"), B.data, j_outer * 1024, 1024, 1), 16, 64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gemv_impl():\n",
        "    cc_code = \"\"\"\n",
        "      extern \"C\" int gemv_update(float *cc, float *aa, float *bb, int m, int l, int stride) {\n",
        "        for (int i = 0; i < m; ++i) {\n",
        "            for (int j = 0; j < l; ++j) {\n",
        "                cc[i] += aa[j] * bb[i * stride + j];\n",
        "            }\n",
        "        }\n",
        "        return 0;\n",
        "      }\n",
        "    \"\"\"\n",
        "    from tvm.contrib import utils, clang\n",
        "\n",
        "    temp = utils.tempdir()\n",
        "    ll_path = temp.relpath(\"temp.ll\")\n",
        "    # Create LLVM ir from c source code\n",
        "    ll_code = clang.create_llvm(cc_code, output=ll_path)\n",
        "    return ll_code"
      ],
      "metadata": {
        "id": "sKkh1edruU5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s[C].pragma(x, \"import_llvm\", gemv_impl())\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJMM_aAhuV-S",
        "outputId": "eea07a98-1bc9-409c-ee2d-a889d82ecc66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 64), \"float32\"), B: T.Buffer((512, 64), \"float32\"), C: T.Buffer((1024, 512), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        i = T.int32()\n",
            "        T.attr(T.iter_var(i, None, \"DataPar\", \"\"), \"pragma_import_llvm\", metadata[\"tir.StringImm\"][0])\n",
            "        for i, j_outer in T.grid(1024, 32):\n",
            "            T.call_extern(\"int32\", \"gemv_update\", T.tvm_access_ptr(T.type_annotation(\"float32\"), C.data, i * 512 + j_outer * 16, 16, 2), T.tvm_access_ptr(T.type_annotation(\"float32\"), A.data, i * 64, 64, 1), T.tvm_access_ptr(T.type_annotation(\"float32\"), B.data, j_outer * 1024, 1024, 1), 16, 64, 64)\n",
            "\n",
            "# Metadata omitted. Use show_meta=True in script() method to show it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func = tvm.build(s, [A, B, C], target=\"llvm\", name=\"gemv\")\n",
        "\n",
        "from tvm.topi.utils import get_const_tuple\n",
        "\n",
        "dtype = A.dtype\n",
        "dev = tvm.device(\"cpu\", 0)\n",
        "a = np.random.uniform(size=get_const_tuple(A.shape)).astype(dtype)\n",
        "b = np.random.uniform(size=get_const_tuple(B.shape)).astype(dtype)\n",
        "c = tvm.nd.array(np.zeros(get_const_tuple(C.shape), dtype=dtype), dev)\n",
        "func(tvm.nd.array(a, dev), tvm.nd.array(b, dev), c)\n",
        "tvm.testing.assert_allclose(c.numpy(), np.dot(a, b.T), rtol=1e-3)"
      ],
      "metadata": {
        "id": "6e39nq7hu8Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reduce-update for Tensorize**"
      ],
      "metadata": {
        "id": "zYvrwKnru6nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zo, zi = s[C].split(z, factor=factor)\n",
        "s[C].reorder(x, yo, zo, yi, zi)"
      ],
      "metadata": {
        "id": "EzLaiCUcu9KX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gemv_impl():\n",
        "    cc_code = \"\"\"\n",
        "      extern \"C\" int gemv_update(float *cc, float *aa, float *bb, int m, int l, int stride) {\n",
        "        for (int i = 0; i < m; ++i) {\n",
        "            for (int j = 0; j < l; ++j) {\n",
        "                cc[i] += aa[j] * bb[i * stride + j];\n",
        "            }\n",
        "        }\n",
        "        return 0;\n",
        "      }\n",
        "      extern \"C\" int gemv_reset(float *cc, int m) {\n",
        "        for (int i = 0; i < m; ++i) {\n",
        "            cc[i] = 0.0;\n",
        "        }\n",
        "        return 0;\n",
        "      }\n",
        "    \"\"\"\n",
        "    from tvm.contrib import utils, clang\n",
        "\n",
        "    temp = utils.tempdir()\n",
        "    ll_path = temp.relpath(\"temp.ll\")\n",
        "    # Create LLVM ir from c source code\n",
        "    ll_code = clang.create_llvm(cc_code, output=ll_path)\n",
        "    return ll_code\n",
        "\n",
        "\n",
        "def intrin_gemv(m, l):\n",
        "    a = te.placeholder((l,), name=\"a\")\n",
        "    b = te.placeholder((m, l), name=\"b\")\n",
        "    k = te.reduce_axis((0, l), name=\"k\")\n",
        "    c = te.compute((m,), lambda i: te.sum(a[k] * b[i, k], axis=k), name=\"c\")\n",
        "    Ab = tvm.tir.decl_buffer(a.shape, a.dtype, name=\"A\", offset_factor=1, strides=[1])\n",
        "    Bb = tvm.tir.decl_buffer(b.shape, b.dtype, name=\"B\", offset_factor=1, strides=[te.var(\"s1\"), 1])\n",
        "    Cb = tvm.tir.decl_buffer(c.shape, c.dtype, name=\"C\", offset_factor=1, strides=[1])\n",
        "\n",
        "    def intrin_func(ins, outs):\n",
        "        aa, bb = ins\n",
        "        cc = outs[0]\n",
        "\n",
        "        def _body():\n",
        "            ib = tvm.tir.ir_builder.create()\n",
        "            ib.emit(\n",
        "                tvm.tir.call_extern(\n",
        "                    \"int32\",\n",
        "                    \"gemv_update\",\n",
        "                    cc.access_ptr(\"w\"),\n",
        "                    aa.access_ptr(\"r\"),\n",
        "                    bb.access_ptr(\"r\"),\n",
        "                    m,\n",
        "                    l,\n",
        "                    bb.strides[0],\n",
        "                )\n",
        "            )\n",
        "            return ib.get()\n",
        "\n",
        "        def _reduce_reset():\n",
        "            ib = tvm.tir.ir_builder.create()\n",
        "            ib.emit(tvm.tir.call_extern(\"int32\", \"gemv_reset\", cc.access_ptr(\"w\"), m))\n",
        "            return ib.get()\n",
        "\n",
        "        def _reduce_update():\n",
        "            return _body()\n",
        "\n",
        "        return _body(), _reduce_reset(), _reduce_update()\n",
        "\n",
        "    return te.decl_tensor_intrin(c.op, intrin_func, binds={a: Ab, b: Bb, c: Cb})"
      ],
      "metadata": {
        "id": "VzBsr8uEu93g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemv = intrin_gemv(factor, factor)\n",
        "s[C].tensorize(yi, gemv)\n",
        "s[C].pragma(yo, \"import_llvm\", gemv_impl())\n",
        "\n",
        "func = tvm.build(s, [A, B, C], target=\"llvm\", name=\"gemv\")\n",
        "a = np.random.uniform(size=get_const_tuple(A.shape)).astype(dtype)\n",
        "b = np.random.uniform(size=get_const_tuple(B.shape)).astype(dtype)\n",
        "c = tvm.nd.array(np.zeros(get_const_tuple(C.shape), dtype=dtype), dev)\n",
        "func(tvm.nd.array(a, dev), tvm.nd.array(b, dev), c)\n",
        "tvm.testing.assert_allclose(c.numpy(), np.dot(a, b.T), rtol=1e-3)"
      ],
      "metadata": {
        "id": "LA9pH7bcvqT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compute and Reduce with Tuple Inputs**"
      ],
      "metadata": {
        "id": "8IzWiav7vslX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, print_function\n",
        "\n",
        "\n",
        "import tvm\n",
        "from tvm import te\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6mKRTKdZvu2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Describe Batchwise Computation**"
      ],
      "metadata": {
        "id": "DZzaXV6Rv1wZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = te.var(\"n\")\n",
        "m = te.var(\"m\")\n",
        "A0 = te.placeholder((m, n), name=\"A0\")\n",
        "A1 = te.placeholder((m, n), name=\"A1\")\n",
        "B0, B1 = te.compute((m, n), lambda i, j: (A0[i, j] + 2, A1[i, j] * 3), name=\"B\")\n",
        "\n",
        "# The generated IR code would be:\n",
        "s = te.create_schedule(B0.op)\n",
        "print(tvm.lower(s, [A0, A1, B0, B1], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIv4-GmJv1Wd",
        "outputId": "0069a005-1cb7-4336-9ff6-b7780c3d4b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A0: T.handle, A1: T.handle, B: T.handle, B_1: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        m, n = T.int32(), T.int32()\n",
            "        A0_1 = T.match_buffer(A0, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        A1_1 = T.match_buffer(A1, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        B_2 = T.match_buffer(B, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        B_3 = T.match_buffer(B_1, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        for i, j in T.grid(m, n):\n",
            "            B_4 = T.Buffer((B_2.strides[0] * m,), data=B_2.data, buffer_type=\"auto\")\n",
            "            A0_2 = T.Buffer((A0_1.strides[0] * m,), data=A0_1.data, buffer_type=\"auto\")\n",
            "            B_4[i * B_2.strides[0] + j * B_2.strides[1]] = A0_2[i * A0_1.strides[0] + j * A0_1.strides[1]] + T.float32(2)\n",
            "            B_5 = T.Buffer((B_3.strides[0] * m,), data=B_3.data, buffer_type=\"auto\")\n",
            "            A1_2 = T.Buffer((A1_1.strides[0] * m,), data=A1_1.data, buffer_type=\"auto\")\n",
            "            B_5[i * B_3.strides[0] + j * B_3.strides[1]] = A1_2[i * A1_1.strides[0] + j * A1_1.strides[1]] * T.float32(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Describe Reduction with Collaborative Inputs**"
      ],
      "metadata": {
        "id": "G3Oylynxv8u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x and y are the operands of reduction, both of them is a tuple of index\n",
        "# and value.\n",
        "def fcombine(x, y):\n",
        "    lhs = tvm.tir.Select((x[1] >= y[1]), x[0], y[0])\n",
        "    rhs = tvm.tir.Select((x[1] >= y[1]), x[1], y[1])\n",
        "    return lhs, rhs\n",
        "\n",
        "\n",
        "# our identity element also need to be a tuple, so `fidentity` accepts\n",
        "# two types as inputs.\n",
        "def fidentity(t0, t1):\n",
        "    return tvm.tir.const(-1, t0), tvm.te.min_value(t1)\n",
        "\n",
        "\n",
        "argmax = te.comm_reducer(fcombine, fidentity, name=\"argmax\")\n",
        "\n",
        "# describe the reduction computation\n",
        "m = te.var(\"m\")\n",
        "n = te.var(\"n\")\n",
        "idx = te.placeholder((m, n), name=\"idx\", dtype=\"int32\")\n",
        "val = te.placeholder((m, n), name=\"val\", dtype=\"int32\")\n",
        "k = te.reduce_axis((0, n), \"k\")\n",
        "T0, T1 = te.compute((m,), lambda i: argmax((idx[i, k], val[i, k]), axis=k), name=\"T\")\n",
        "\n",
        "# the generated IR code would be:\n",
        "s = te.create_schedule(T0.op)\n",
        "print(tvm.lower(s, [idx, val, T0, T1], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir_HTha0v7ok",
        "outputId": "648a8bb5-b7d4-457f-a575-2d161b7b3dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(idx: T.handle, val: T.handle, T: T.handle, T_1: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        m, n = T.int32(), T.int32()\n",
            "        idx_1 = T.match_buffer(idx, (m, n), \"int32\", strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        val_1 = T.match_buffer(val, (m, n), \"int32\", strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        T_2 = T.match_buffer(T, (m,), \"int32\", strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        T_3 = T.match_buffer(T_1, (m,), \"int32\", strides=(\"stride\",), buffer_type=\"auto\")\n",
            "        for i in range(m):\n",
            "            T_4 = T.Buffer((T_2.strides[0] * m,), \"int32\", data=T_2.data, buffer_type=\"auto\")\n",
            "            T_4[i * T_2.strides[0]] = -1\n",
            "            T_5 = T.Buffer((T_3.strides[0] * m,), \"int32\", data=T_3.data, buffer_type=\"auto\")\n",
            "            T_5[i * T_3.strides[0]] = -2147483648\n",
            "            for k in range(n):\n",
            "                val_2 = T.Buffer((val_1.strides[0] * m,), \"int32\", data=val_1.data, buffer_type=\"auto\")\n",
            "                idx_2 = T.Buffer((idx_1.strides[0] * m,), \"int32\", data=idx_1.data, buffer_type=\"auto\")\n",
            "                T_4[i * T_2.strides[0]] = T.if_then_else(val_2[i * val_1.strides[0] + k * val_1.strides[1]] <= T_5[i * T_3.strides[0]], T_4[i * T_2.strides[0]], idx_2[i * idx_1.strides[0] + k * idx_1.strides[1]])\n",
            "                T_5[i * T_3.strides[0]] = T.if_then_else(val_2[i * val_1.strides[0] + k * val_1.strides[1]] <= T_5[i * T_3.strides[0]], T_5[i * T_3.strides[0]], val_2[i * val_1.strides[0] + k * val_1.strides[1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schedule Operation with Tuple Inputs**"
      ],
      "metadata": {
        "id": "JNg_YyMKwtAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = te.var(\"n\")\n",
        "m = te.var(\"m\")\n",
        "A0 = te.placeholder((m, n), name=\"A0\")\n",
        "B0, B1 = te.compute((m, n), lambda i, j: (A0[i, j] + 2, A0[i, j] * 3), name=\"B\")\n",
        "A1 = te.placeholder((m, n), name=\"A1\")\n",
        "C = te.compute((m, n), lambda i, j: A1[i, j] + B0[i, j], name=\"C\")\n",
        "\n",
        "s = te.create_schedule(C.op)\n",
        "s[B0].compute_at(s[C], C.op.axis[0])\n",
        "# as you can see in the below generated IR code:\n",
        "print(tvm.lower(s, [A0, A1, C], simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6j064xDwuc-",
        "outputId": "be60304a-9e46-4111-fe2b-2924312a3caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A0: T.handle, A1: T.handle, C: T.handle):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        m, n = T.int32(), T.int32()\n",
            "        A0_1 = T.match_buffer(A0, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        A1_1 = T.match_buffer(A1, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        C_1 = T.match_buffer(C, (m, n), strides=(\"stride\", \"stride\"), buffer_type=\"auto\")\n",
            "        B_v0 = T.allocate([n], \"float32\", \"global\")\n",
            "        B_v1 = T.allocate([n], \"float32\", \"global\")\n",
            "        for i in range(m):\n",
            "            B_v0_1 = T.Buffer((n,), data=B_v0)\n",
            "            for j in range(n):\n",
            "                A0_2 = T.Buffer((A0_1.strides[0] * m,), data=A0_1.data, buffer_type=\"auto\")\n",
            "                B_v0_1[j] = A0_2[i * A0_1.strides[0] + j * A0_1.strides[1]] + T.float32(2)\n",
            "                B_v1_1 = T.Buffer((n,), data=B_v1)\n",
            "                B_v1_1[j] = A0_2[i * A0_1.strides[0] + j * A0_1.strides[1]] * T.float32(3)\n",
            "            for j in range(n):\n",
            "                C_2 = T.Buffer((C_1.strides[0] * m,), data=C_1.data, buffer_type=\"auto\")\n",
            "                A1_2 = T.Buffer((A1_1.strides[0] * m,), data=A1_1.data, buffer_type=\"auto\")\n",
            "                C_2[i * C_1.strides[0] + j * C_1.strides[1]] = A1_2[i * A1_1.strides[0] + j * A1_1.strides[1]] + B_v0_1[j]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Use Tensor Expression Debug Display (TEDD) for Visualization**"
      ],
      "metadata": {
        "id": "fnTAt7urw6uG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm\n",
        "from tvm import te\n",
        "from tvm import topi\n",
        "from tvm.contrib import tedd"
      ],
      "metadata": {
        "id": "2_jsVA2Lw8X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = 1\n",
        "in_channel = 256\n",
        "in_size = 32\n",
        "num_filter = 256\n",
        "kernel = 3\n",
        "stride = 1\n",
        "padding = \"SAME\"\n",
        "dilation = 1\n",
        "\n",
        "A = te.placeholder((in_size, in_size, in_channel, batch), name=\"A\")\n",
        "W = te.placeholder((kernel, kernel, in_channel, num_filter), name=\"W\")\n",
        "B = te.placeholder((1, num_filter, 1), name=\"bias\")\n",
        "\n",
        "with tvm.target.Target(\"llvm\"):\n",
        "    t_conv = topi.nn.conv2d_hwcn(A, W, stride, padding, dilation)\n",
        "    t_bias = topi.add(t_conv, B)\n",
        "    t_relu = topi.nn.relu(t_bias)\n",
        "    s = topi.generic.schedule_conv2d_hwcn([t_relu])"
      ],
      "metadata": {
        "id": "8M0QPSuNxBPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tedd.viz_dataflow_graph(s, dot_file_path=\"/tmp/dfg.dot\")\n",
        "# tedd.viz_dataflow_graph(s, show_svg = True)"
      ],
      "metadata": {
        "id": "j0aw_cJTxEA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/dmlc/web-data/raw/main/tvm/tutorial/tedd_dfg.png\" align=\"center\">\n"
      ],
      "metadata": {
        "id": "okPSbW5CxlXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tedd.viz_schedule_tree(s, dot_file_path=\"/tmp/scheduletree.dot\")\n",
        "# tedd.viz_schedule_tree(s, show_svg = True)"
      ],
      "metadata": {
        "id": "EIWKZnXoxI_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = s.normalize()\n",
        "tedd.viz_schedule_tree(s, dot_file_path=\"/tmp/scheduletree2.dot\")\n",
        "# tedd.viz_schedule_tree(s, show_svg = True)"
      ],
      "metadata": {
        "id": "_P3NPsVyxKe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/dmlc/web-data/raw/main/tvm/tutorial/tedd_st.png\" align=\"center\">"
      ],
      "metadata": {
        "id": "QnZghbXKxh36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tedd.viz_itervar_relationship_graph(s, dot_file_path=\"/tmp/itervar.dot\")\n",
        "# tedd.viz_itervar_relationship_graph(s, show_svg = True)"
      ],
      "metadata": {
        "id": "ElYCxqPbxRRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/dmlc/web-data/raw/main/tvm/tutorial/tedd_itervar_rel.png\" align=\"center\">"
      ],
      "metadata": {
        "id": "marUlCruxg9u"
      }
    }
  ]
}