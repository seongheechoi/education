{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seongheechoi/education/blob/main/%EC%8B%A4%EC%8A%B5_1_2_compiling_and_optimizing_a_model_with_the_python_interface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TVM 실습자료 1: Compiling and Optimizing a Model with the Python Interface (AutoTVM)**"
      ],
      "metadata": {
        "id": "obNG1RuRPSxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4\n",
        "import numpy as np\n",
        "print(np.__version__)\n",
        "!pip list | grep numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LRYwKw_rajO",
        "outputId": "d7f780fb-e16b-421d-ef1c-bbc913a0c5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "1.26.4\n",
            "numpy                                 1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --upgrade pip\n",
        "!pip install apache-tvm\n",
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8BbqGhgm6BN",
        "outputId": "b0e83465-43fd-4abf-922b-b8aa8f73e978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.1.1\n",
            "Collecting apache-tvm\n",
            "  Downloading apache_tvm-0.14.dev273-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (25.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (1.26.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (1.15.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (6.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from apache-tvm) (4.14.1)\n",
            "Downloading apache_tvm-0.14.dev273-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: apache-tvm\n",
            "Successfully installed apache-tvm-0.14.dev273\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.1)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from tvm.contrib.download import download_testdata\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tvm.relay as relay\n",
        "import tvm\n",
        "from tvm.contrib import graph_executor"
      ],
      "metadata": {
        "id": "zgfuxwRgqsuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_url = (\n",
        "    \"https://github.com/onnx/models/raw/b9a54e89508f101a1611cd64f4ef56b9cb62c7cf/\"\n",
        "    \"vision/classification/resnet/model/\"\n",
        "    \"resnet50-v2-7.onnx\"\n",
        ")\n",
        "\n",
        "model_path = download_testdata(model_url, \"resnet50-v2-7.onnx\", module=\"onnx\")\n",
        "onnx_model = onnx.load(model_path)\n",
        "\n",
        "# Seed numpy's RNG to get consistent results\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "AK0RIEF3rCwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_url = \"https://s3.amazonaws.com/model-server/inputs/kitten.jpg\"\n",
        "img_path = download_testdata(img_url, \"imagenet_cat.png\", module=\"data\")\n",
        "\n",
        "# Resize it to 224x224\n",
        "resized_image = Image.open(img_path).resize((224, 224))\n",
        "img_data = np.asarray(resized_image).astype(\"float32\")\n",
        "\n",
        "# Our input image is in HWC layout while ONNX expects CHW input, so convert the array\n",
        "img_data = np.transpose(img_data, (2, 0, 1))\n",
        "\n",
        "# Normalize according to the ImageNet input specification\n",
        "imagenet_mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
        "imagenet_stddev = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
        "norm_img_data = (img_data / 255 - imagenet_mean) / imagenet_stddev\n",
        "\n",
        "# Add the batch dimension, as we are expecting 4-dimensional input: NCHW.\n",
        "img_data = np.expand_dims(norm_img_data, axis=0)"
      ],
      "metadata": {
        "id": "VHbO1W6zrNet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"llvm\""
      ],
      "metadata": {
        "id": "SXG6zBn2tncn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The input name may vary across model types. You can use a tool\n",
        "# like Netron to check input names\n",
        "input_name = \"data\"\n",
        "shape_dict = {input_name: img_data.shape}\n",
        "\n",
        "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
        "\n",
        "with tvm.transform.PassContext(opt_level=3):\n",
        "    lib = relay.build(mod, target=target, params=params)\n",
        "\n",
        "dev = tvm.device(str(target), 0)\n",
        "module = graph_executor.GraphModule(lib[\"default\"](dev))"
      ],
      "metadata": {
        "id": "Xf8Hoy8htofH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19da67e-5579-4d3f-b54d-b263d2578036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autotvm:One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = \"float32\"\n",
        "module.set_input(input_name, img_data)\n",
        "module.run()\n",
        "output_shape = (1, 1000)\n",
        "tvm_output = module.get_output(0, tvm.nd.empty(output_shape)).numpy()"
      ],
      "metadata": {
        "id": "8K5vlcSstyNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "timing_number = 10\n",
        "timing_repeat = 10\n",
        "unoptimized = (\n",
        "    np.array(timeit.Timer(lambda: module.run()).repeat(repeat=timing_repeat, number=timing_number))\n",
        "    * 1000\n",
        "    / timing_number\n",
        ")\n",
        "unoptimized = {\n",
        "    \"mean\": np.mean(unoptimized),\n",
        "    \"median\": np.median(unoptimized),\n",
        "    \"std\": np.std(unoptimized),\n",
        "}\n",
        "\n",
        "print(unoptimized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBBKC1uxt1fk",
        "outputId": "c64353dc-e675-458c-c4c0-cc4edf02908a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mean': 685.8559246499991, 'median': 689.0373234499989, 'std': 62.02503789378133}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# Download a list of labels\n",
        "labels_url = \"https://s3.amazonaws.com/onnx-model-zoo/synset.txt\"\n",
        "labels_path = download_testdata(labels_url, \"synset.txt\", module=\"data\")\n",
        "\n",
        "with open(labels_path, \"r\") as f:\n",
        "    labels = [l.rstrip() for l in f]\n",
        "\n",
        "# Open the output and read the output tensor\n",
        "scores = softmax(tvm_output)\n",
        "scores = np.squeeze(scores)\n",
        "ranks = np.argsort(scores)[::-1]\n",
        "for rank in ranks[0:5]:\n",
        "    print(\"class='%s' with probability=%f\" % (labels[rank], scores[rank]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2-KttUAuQBd",
        "outputId": "60f8df4d-a057-4fe2-ec89-47fff9c040f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class='n02123045 tabby, tabby cat' with probability=0.621103\n",
            "class='n02123159 tiger cat' with probability=0.356379\n",
            "class='n02124075 Egyptian cat' with probability=0.019712\n",
            "class='n02129604 tiger, Panthera tigris' with probability=0.001215\n",
            "class='n04040759 radiator' with probability=0.000262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm.auto_scheduler as auto_scheduler\n",
        "from tvm.autotvm.tuner import XGBTuner\n",
        "from tvm import autotvm\n",
        "\n",
        "number = 10\n",
        "repeat = 1\n",
        "min_repeat_ms = 0  # since we're tuning on a CPU, can be set to 0\n",
        "timeout = 10  # in seconds\n",
        "\n",
        "# create a TVM runner\n",
        "runner = autotvm.LocalRunner(\n",
        "    number=number,\n",
        "    repeat=repeat,\n",
        "    timeout=timeout,\n",
        "    min_repeat_ms=min_repeat_ms,\n",
        "    enable_cpu_cache_flush=True,\n",
        ")"
      ],
      "metadata": {
        "id": "yyuZ4_s8urPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuning_option = {\n",
        "    \"tuner\": \"xgb\",\n",
        "    \"trials\": 20,\n",
        "    \"early_stopping\": 100,\n",
        "    \"measure_option\": autotvm.measure_option(\n",
        "        builder=autotvm.LocalBuilder(build_func=\"default\"), runner=runner\n",
        "    ),\n",
        "    \"tuning_records\": \"resnet-50-v2-autotuning.json\",\n",
        "}"
      ],
      "metadata": {
        "id": "qm23g2Y8vIfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# begin by extracting the tasks from the onnx model\n",
        "tasks = autotvm.task.extract_from_program(mod[\"main\"], target=target, params=params)\n",
        "\n",
        "# Tune the extracted tasks sequentially.\n",
        "for i, task in enumerate(tasks):\n",
        "    prefix = \"[Task %2d/%2d] \" % (i + 1, len(tasks))\n",
        "\n",
        "    # create tuner\n",
        "    tuner_obj = XGBTuner(task, loss_type=\"reg\")\n",
        "\n",
        "    tuner_obj.tune(\n",
        "        n_trial=min(tuning_option[\"trials\"], len(task.config_space)),\n",
        "        early_stopping=tuning_option[\"early_stopping\"],\n",
        "        measure_option=tuning_option[\"measure_option\"],\n",
        "        callbacks=[\n",
        "            autotvm.callback.progress_bar(tuning_option[\"trials\"], prefix=prefix),\n",
        "            autotvm.callback.log_to_file(tuning_option[\"tuning_records\"]),\n",
        "        ],\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "GSB2BEC2vK-S",
        "outputId": "188ce10b-8901-443e-bdc6-832da3e321a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-2440345245.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# begin by extracting the tasks from the onnx model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautotvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_from_program\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"main\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Tune the extracted tasks sequentially.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tvm/autotvm/task/relay_integration.py\u001b[0m in \u001b[0;36mextract_from_program\u001b[0;34m(mod, params, target, target_host, ops)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m     83\u001b[0m     \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanon_target_and_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_host\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mextract_from_multiple_program\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tvm/autotvm/task/relay_integration.py\u001b[0m in \u001b[0;36mextract_from_multiple_program\u001b[0;34m(mods, params, target, target_host, ops)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mbuild_thread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mbuild_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mbuild_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mrelay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mte_compiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# Clear the warning message cache in FallbackContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url='https://raw.githubusercontent.com/simey1128/LG_DIC_TVM/refs/heads/main/1_2_resnet-50-v2-autotuning.json'\n",
        "response = requests.get(url)\n",
        "\n",
        "with open('resnet-50-v2-autotuning.json', 'wb') as f:\n",
        "  f.write(response.content)"
      ],
      "metadata": {
        "id": "aimRxX03T3iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with autotvm.apply_history_best(tuning_option[\"tuning_records\"]):\n",
        "    with tvm.transform.PassContext(opt_level=3, config={}):\n",
        "        lib = relay.build(mod, target=target, params=params)\n",
        "\n",
        "dev = tvm.device(str(target), 0)\n",
        "module = graph_executor.GraphModule(lib[\"default\"](dev))"
      ],
      "metadata": {
        "id": "TphY8a5a3fXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = \"float32\"\n",
        "module.set_input(input_name, img_data)\n",
        "module.run()\n",
        "output_shape = (1, 1000)\n",
        "tvm_output = module.get_output(0, tvm.nd.empty(output_shape)).numpy()\n",
        "\n",
        "scores = softmax(tvm_output)\n",
        "scores = np.squeeze(scores)\n",
        "ranks = np.argsort(scores)[::-1]\n",
        "for rank in ranks[0:5]:\n",
        "    print(\"class='%s' with probability=%f\" % (labels[rank], scores[rank]))"
      ],
      "metadata": {
        "id": "SCM58CtQ3kJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814c2fd3-6538-400d-8ba3-94a9cbec99b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class='n02123045 tabby, tabby cat' with probability=0.621103\n",
            "class='n02123159 tiger cat' with probability=0.356379\n",
            "class='n02124075 Egyptian cat' with probability=0.019712\n",
            "class='n02129604 tiger, Panthera tigris' with probability=0.001215\n",
            "class='n04040759 radiator' with probability=0.000262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "timing_number = 10\n",
        "timing_repeat = 10\n",
        "optimized = (\n",
        "    np.array(timeit.Timer(lambda: module.run()).repeat(repeat=timing_repeat, number=timing_number))\n",
        "    * 1000\n",
        "    / timing_number\n",
        ")\n",
        "optimized = {\"mean\": np.mean(optimized), \"median\": np.median(optimized), \"std\": np.std(optimized)}\n",
        "\n",
        "\n",
        "print(\"optimized: %s\" % (optimized))\n",
        "print(\"unoptimized: %s\" % (unoptimized))"
      ],
      "metadata": {
        "id": "UbXR3jMq4Juu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820eeb0d-dc24-4455-aa2b-5d6497817b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimized: {'mean': 569.2334612899981, 'median': 537.2051128999942, 'std': 55.52933701731525}\n",
            "unoptimized: {'mean': 685.8559246499991, 'median': 689.0373234499989, 'std': 62.02503789378133}\n"
          ]
        }
      ]
    }
  ]
}